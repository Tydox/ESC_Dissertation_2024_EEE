{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-17T11:45:56.105396Z",
     "start_time": "2024-06-17T11:45:56.100452Z"
    }
   },
   "outputs": [],
   "source": [
    "# note: text\n",
    "# fixed: text\n",
    "# fix me: text\n",
    "# error: text\n",
    "# summary: text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "outputs": [],
   "source": [
    "#Loader function for Pytorch Dataset Folder thingy\n",
    "def load_data(path: str):\n",
    "    #print(f\"Loading file: {path}\")\n",
    "    tensor = torch.load(path)\n",
    "    #tensor = tensor.float()\n",
    "    #print(f\"Loaded tensor type: {type(tensor)} {tensor.type()}\")\n",
    "    return tensor\n",
    "\n",
    "\n",
    "#ERROR DOESNT FULLY WORK WITH DATASET - IDK WHY - I GAVE UP FOR NOW\n",
    "#FIXME THIS DOES WORK AS A REGULAR REMAP AND I USE THIS FOR PRINTING DATA\n",
    "#NOTE TO SELF: DO NOT DELETE THIS FUNCTION\n",
    "# Define a custom transform to convert labels from float to int\n",
    "def label_remap(label):\n",
    "    label_mapping = {\n",
    "            0: 47,\n",
    "            1: 23,\n",
    "            2: 27,\n",
    "            3: 34,\n",
    "            4: 43,\n",
    "            5: 5,\n",
    "            6: 41,\n",
    "            7: 14,\n",
    "            8: 46,\n",
    "            9: 22,\n",
    "            10: 37,\n",
    "            11: 38,\n",
    "            12: 24,\n",
    "            13: 3,\n",
    "            14: 12,\n",
    "            15: 13,\n",
    "            16: 9,\n",
    "            17: 20,\n",
    "            18: 0,\n",
    "            19: 33,\n",
    "            20: 30,\n",
    "            21: 29,\n",
    "            22: 44,\n",
    "            23: 48,\n",
    "            24: 25,\n",
    "            25: 4,\n",
    "            26: 39,\n",
    "            27: 49,\n",
    "            28: 40,\n",
    "            29: 6,\n",
    "            30: 7,\n",
    "            31: 32,\n",
    "            32: 26,\n",
    "            33: 31,\n",
    "            34: 2,\n",
    "            35: 17,\n",
    "            36: 10,\n",
    "            37: 1,\n",
    "            38: 11,\n",
    "            39: 8,\n",
    "            40: 42,\n",
    "            41: 21,\n",
    "            42: 28,\n",
    "            43: 19,\n",
    "            44: 18,\n",
    "            45: 45,\n",
    "            46: 36,\n",
    "            47: 35,\n",
    "            48: 15,\n",
    "            49: 16\n",
    "    }\n",
    "    return torch.tensor(int(label_mapping[label]))\n",
    "\n",
    "\n",
    "#Summary: Print All Samples in Dataloader\n",
    "#Summary: Data Label OG = this is the published index labling, dog = 4\n",
    "#Summary; because pytorch sorts the data, dog = 18 in Dataloader,\n",
    "#Summary: so if i want to double check that the labels are correct, I have to use label_remap() function to convert the pytorch label number to the original\n",
    "#Summary: this doesnt really matter, all the code below was to just do a double check that everything is correct\n",
    "\n",
    "def print_data_loader(_dataloader, _stop,class_names):\n",
    "    _idx = f\"{'#':<{4}} | \"\n",
    "    _dshape = f\"{'Data Shape:[c,  t,   w]':<{24}} | \"\n",
    "    _lshape = f\"{'Label Shape':<{15}} | \"\n",
    "    _ddtype = f\"{'Data DataType':<{13}} | \"\n",
    "    _dlabel1 = f\"{'Data Label OG':<{13}} | \"\n",
    "    _dlabel2 = f\"{'Data Label Py':<{13}} | \"\n",
    "    _dlabel3 = f\"{'Data Label ':<{20}} | \"\n",
    "    _ldtype = f\"{'Label Type':<{22}} | \"\n",
    "    _dpath = f\"{'Data Path + Label PyTorch Value':<{60}} | \"\n",
    "\n",
    "    print(f\"{_idx}{_dshape}{_lshape}{_ddtype}{_dlabel1}{_dlabel2}{_dlabel3}{_dpath}{_ldtype}\")\n",
    "\n",
    "    #Note: CREATE AN ITERATOR FOR DATALOADER\n",
    "    _data_iter = iter(_dataloader)\n",
    "    #next(_data_iter)\n",
    "    counter = 1  #counter when to stop for loop\n",
    "    #NOTE: GO OVER ALL SAMPLES IN ITERATOR\n",
    "    for (_data, _label) in _data_iter:\n",
    "        #_data_iter = iter(test_dataloader)\n",
    "        _rnd_idx = _data_iter._sampler_iter.gi_frame.f_locals['idx']\n",
    "        _sample_idx = _data_iter._dataset.indices[_rnd_idx]\n",
    "        #numm = _data_iter._index_sampler.sampler.data_source.indices[num] #incorrect location\n",
    "        _path = test_dataset.dataset.samples[_sample_idx]\n",
    "\n",
    "        #NOTE: This is for debug to check that it is the same samples values\n",
    "        #_amy_data = my_data_set[NUM2][0]\n",
    "        #_amy_dataog =  _data[0]\n",
    "        #diff =sum(sum(_amy_data - _amy_dataog)) \n",
    "        #print(diff)\n",
    "        #print(_path)\n",
    "        _idx = f\"{counter:<{4}} | \"\n",
    "        _dshape = f\"{str(_data.shape):<{24}} | \"  # = [batch_size, color_channels, height, width]\"\n",
    "        _lshape = f\"{str(_label.shape):<{15}} | \"\n",
    "        _ddtype = f\"{str(_data.dtype):<{13}} | \"\n",
    "        _dlabel1 = f\"{str(label_remap(int(_label[0]))):<{13}} | \"\n",
    "        _dlabel2 = f\"{str(_label):<{13}} | \"\n",
    "        _dlabel3 = f\"{str(class_names[_label]):<{20}} | \"\n",
    "        _ldtype = f\"{str(type(_label)):<{22}} | \"\n",
    "        _dpath = f\"{str(_path).split('/', 6)[6]:<{60}} | \"\n",
    "\n",
    "        print(f\"{_idx}{_dshape}{_lshape}{_ddtype}{_dlabel1}{_dlabel2}{_dlabel3}{_dpath}{_ldtype}\")\n",
    "\n",
    "        if counter == _stop:\n",
    "            break\n",
    "        else:\n",
    "            counter = counter + 1\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-17T11:45:56.333359Z",
     "start_time": "2024-06-17T11:45:56.330292Z"
    }
   },
   "id": "55baaa3bcda72ffd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# ALL CODE ABOVE IS FUNCTIONS FROM MFCC_DATA_IMPORT"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "edb21a47bc95f30a"
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "outputs": [],
   "source": [
    "import os\n",
    "OutputFolder =\"/Users/daniel/Desktop/Github/ESC_Dissertation_2024_EEE/MFCC/tensor3c/\"\n",
    "# Step 1: Create a dataset from the new organized folder\n",
    "\n",
    "#from torchvision import transforms\n",
    "#NHWC2NCHW = transforms.Compose([transforms.Lambda(lambda x: x.permute(0, 3, 1, 2))])  # from NHWC to NCHW\n",
    "# Define a custom transform to add the extra dimension\n",
    "# test_transform = transforms.Compose([\n",
    "#     transforms.Lambda(lambda x: x.unsqueeze(0))  # Adds an extra dimension, making it [1, C, H, W]\n",
    "# ])\n",
    "import torch\n",
    "from torchvision import datasets\n",
    "\n",
    "my_data_set = datasets.DatasetFolder(\n",
    "        root = OutputFolder,\n",
    "        loader = load_data,\n",
    "        transform = None, #use \"test_transform\" only if using coeff because its missing channels=1 dimention  #our transformation for data\n",
    "        target_transform = None,\n",
    "        extensions = ('.pt',)\n",
    ")\n",
    "#my_data_set.class_to_idx\n",
    "#Step 2\n",
    "# Determine the sizes for training and testing splits\n",
    "# And Split the dataset\n",
    "\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "train_size = int(0.7 * len(my_data_set))\n",
    "test_size = len(my_data_set) - train_size\n",
    "\n",
    "train_dataset, test_dataset = random_split(my_data_set, [train_size, test_size])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-17T11:45:56.668962Z",
     "start_time": "2024-06-17T11:45:56.659374Z"
    }
   },
   "id": "e97881811308182d"
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "outputs": [],
   "source": [
    "#step 3\n",
    "# Turn train\\test Datasets into train\\test DataLoaders\n",
    "\n",
    "#import os\n",
    "#NUM_OF_WORKERS = os.cpu_count() #this is used on collab when I want to use all max cpu power\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "BATCH_SIZE = 20\n",
    "train_dataloader = DataLoader(dataset = train_dataset,\n",
    "                              batch_size = BATCH_SIZE,  # how many samples per batch?\n",
    "                              #num_workers=1,#ERROR THIS DOESNT WORK ON LAPTOP BUT WORKS ON COLLAB # how many CPU subprocesses to use for data loading? (higher = more)\n",
    "                              shuffle = True)  # shuffle the data?\n",
    "\n",
    "test_dataloader = DataLoader(dataset = test_dataset,\n",
    "                             batch_size = BATCH_SIZE,  # how many samples per batch?\n",
    "                             #num_workers=1,#ERROR THIS DOESNT WORK ON LAPTOP BUT WORKS ON COLLAB # how many CPU subprocesses to use for data loading? (higher = more)\n",
    "                             shuffle = True)  # shuffle the data?"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-17T11:45:56.978861Z",
     "start_time": "2024-06-17T11:45:56.976174Z"
    }
   },
   "id": "9f7f586a6ec2bbb6"
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Class Label': Label Number \n",
      "{'airplane': 0, 'breathing': 1, 'brushing_teeth': 2, 'can_opening': 3, 'car_horn': 4, 'cat': 5, 'chainsaw': 6, 'chirping_birds': 7, 'church_bells': 8, 'clapping': 9, 'clock_alarm': 10, 'clock_tick': 11, 'coughing': 12, 'cow': 13, 'crackling_fire': 14, 'crickets': 15, 'crow': 16, 'crying_baby': 17, 'dog': 18, 'door_wood_creaks': 19, 'door_wood_knock': 20, 'drinking_sipping': 21, 'engine': 22, 'fireworks': 23, 'footsteps': 24, 'frog': 25, 'glass_breaking': 26, 'hand_saw': 27, 'helicopter': 28, 'hen': 29, 'insects': 30, 'keyboard_typing': 31, 'laughing': 32, 'mouse_click': 33, 'pig': 34, 'pouring_water': 35, 'rain': 36, 'rooster': 37, 'sea_waves': 38, 'sheep': 39, 'siren': 40, 'sneezing': 41, 'snoring': 42, 'thunderstorm': 43, 'toilet_flush': 44, 'train': 45, 'vacuum_cleaner': 46, 'washing_machine': 47, 'water_drops': 48, 'wind': 49}\n"
     ]
    }
   ],
   "source": [
    "class_names = my_data_set.classes\n",
    "class_dict = my_data_set.class_to_idx\n",
    "print(f\"'Class Label': Label Number \\n{class_dict}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-17T11:45:57.578229Z",
     "start_time": "2024-06-17T11:45:57.575645Z"
    }
   },
   "id": "ae10b1acb2c9da55"
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train DataLoader Samples:\t70,\t\tTest DataLoader Samples:\t30.\n",
      "Train DataSet Samples:\t\t1400,\t\tTest DataSet Samples:\t\t600.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train DataLoader Samples:\\t{len(train_dataloader)},\\t\\tTest DataLoader Samples:\\t{len(test_dataloader)}.\")\n",
    "print(f\"Train DataSet Samples:\\t\\t{len(train_dataset)},\\t\\tTest DataSet Samples:\\t\\t{len(test_dataset)}.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-17T11:45:58.090123Z",
     "start_time": "2024-06-17T11:45:58.087271Z"
    }
   },
   "id": "d9d11625dbe18dbb"
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#    | Data Shape:[c,  t,   w]  | Label Shape     | Data DataType | Data Label OG | Data Label Py | Data Label           | Data Path + Label PyTorch Value                              | Label Type             | \n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "only integer tensors of a single element can be converted to an index",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[177], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mprint_data_loader\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtest_dataloader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43mclass_names\u001B[49m\u001B[43m \u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;66;03m# DOESNT WORK WHEN BATCH SIZE IS > 1\u001B[39;00m\n",
      "Cell \u001B[0;32mIn[172], line 113\u001B[0m, in \u001B[0;36mprint_data_loader\u001B[0;34m(_dataloader, _stop, class_names)\u001B[0m\n\u001B[1;32m    111\u001B[0m _dlabel1 \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mstr\u001B[39m(label_remap(\u001B[38;5;28mint\u001B[39m(_label[\u001B[38;5;241m0\u001B[39m])))\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m<\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;241m13\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m | \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    112\u001B[0m _dlabel2 \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mstr\u001B[39m(_label)\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m<\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;241m13\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m | \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m--> 113\u001B[0m _dlabel3 \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mstr\u001B[39m(\u001B[43mclass_names\u001B[49m\u001B[43m[\u001B[49m\u001B[43m_label\u001B[49m\u001B[43m]\u001B[49m)\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m<\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;241m20\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m | \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    114\u001B[0m _ldtype \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mtype\u001B[39m(_label))\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m<\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;241m22\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m | \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    115\u001B[0m _dpath \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mstr\u001B[39m(_path)\u001B[38;5;241m.\u001B[39msplit(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m/\u001B[39m\u001B[38;5;124m'\u001B[39m,\u001B[38;5;250m \u001B[39m\u001B[38;5;241m6\u001B[39m)[\u001B[38;5;241m6\u001B[39m]\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m<\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;241m60\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m | \u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "\u001B[0;31mTypeError\u001B[0m: only integer tensors of a single element can be converted to an index"
     ]
    }
   ],
   "source": [
    "print_data_loader(test_dataloader, 1,class_names ) # DOESNT WORK WHEN BATCH SIZE IS > 1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-17T11:46:00.598319Z",
     "start_time": "2024-06-17T11:46:00.570379Z"
    }
   },
   "id": "d9209d1f27d7a9ec"
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#    | Data Shape:[N, c,  h,   w] | Label Shape     | Data DataType | Data Label OG | Data Label Py | Data Label           | Data Path + Label PyTorch Value                              | Label Type             | \n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "only integer tensors of a single element can be converted to an index",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[178], line 40\u001B[0m\n\u001B[1;32m     38\u001B[0m _dlabel1 \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mstr\u001B[39m(label_remap(\u001B[38;5;28mint\u001B[39m(_label[\u001B[38;5;241m0\u001B[39m])))\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m<\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;241m13\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m | \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     39\u001B[0m _dlabel2 \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mstr\u001B[39m(_label)\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m<\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;241m13\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m | \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m---> 40\u001B[0m _dlabel3 \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mstr\u001B[39m(\u001B[43mclass_names\u001B[49m\u001B[43m[\u001B[49m\u001B[43m_label\u001B[49m\u001B[43m]\u001B[49m)\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m<\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;241m20\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m | \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     41\u001B[0m _ldtype \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mtype\u001B[39m(_label))\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m<\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;241m22\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m | \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     42\u001B[0m _dpath \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mstr\u001B[39m(_path)\u001B[38;5;241m.\u001B[39msplit(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m/\u001B[39m\u001B[38;5;124m'\u001B[39m,\u001B[38;5;250m \u001B[39m\u001B[38;5;241m6\u001B[39m)[\u001B[38;5;241m6\u001B[39m]\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m<\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;241m60\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m | \u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "\u001B[0;31mTypeError\u001B[0m: only integer tensors of a single element can be converted to an index"
     ]
    }
   ],
   "source": [
    "_dataloader, _stop,class_names = test_dataloader, 1,class_names\n",
    "\n",
    "#print_data_loader(train_dataloader, 5,class_names )\n",
    "_idx = f\"{'#':<{4}} | \"\n",
    "_dshape = f\"{'Data Shape:[N, c,  h,   w]':<{24}} | \"\n",
    "_lshape = f\"{'Label Shape':<{15}} | \"\n",
    "_ddtype = f\"{'Data DataType':<{13}} | \"\n",
    "_dlabel1 = f\"{'Data Label OG':<{13}} | \"\n",
    "_dlabel2 = f\"{'Data Label Py':<{13}} | \"\n",
    "_dlabel3 = f\"{'Data Label ':<{20}} | \"\n",
    "_ldtype = f\"{'Label Type':<{22}} | \"\n",
    "_dpath = f\"{'Data Path + Label PyTorch Value':<{60}} | \"\n",
    "\n",
    "print(f\"{_idx}{_dshape}{_lshape}{_ddtype}{_dlabel1}{_dlabel2}{_dlabel3}{_dpath}{_ldtype}\")\n",
    "\n",
    "#Note: CREATE AN ITERATOR FOR DATALOADER\n",
    "_data_iter = iter(_dataloader)\n",
    "#next(_data_iter)\n",
    "counter = 1  #counter when to stop for loop\n",
    "#NOTE: GO OVER ALL SAMPLES IN ITERATOR\n",
    "for (_data, _label) in _data_iter:\n",
    "    #_data_iter = iter(test_dataloader)\n",
    "    _rnd_idx = _data_iter._sampler_iter.gi_frame.f_locals['idx']\n",
    "    _sample_idx = _data_iter._dataset.indices[_rnd_idx]\n",
    "    #numm = _data_iter._index_sampler.sampler.data_source.indices[num] #incorrect location\n",
    "    _path = test_dataset.dataset.samples[_sample_idx]\n",
    "\n",
    "    #NOTE: This is for debug to check that it is the same samples values\n",
    "    #_amy_data = my_data_set[NUM2][0]\n",
    "    #_amy_dataog =  _data[0]\n",
    "    #diff =sum(sum(_amy_data - _amy_dataog)) \n",
    "    #print(diff)\n",
    "    #print(_path)\n",
    "    _idx = f\"{counter:<{4}} | \"\n",
    "    _dshape = f\"{str(_data.shape):<{24}} | \"  # = [batch_size, color_channels, height, width]\"\n",
    "    _lshape = f\"{str(_label.shape):<{15}} | \"\n",
    "    _ddtype = f\"{str(_data.dtype):<{13}} | \"\n",
    "    _dlabel1 = f\"{str(label_remap(int(_label[0]))):<{13}} | \"\n",
    "    _dlabel2 = f\"{str(_label):<{13}} | \"\n",
    "    _dlabel3 = f\"{str(class_names[_label]):<{20}} | \"\n",
    "    _ldtype = f\"{str(type(_label)):<{22}} | \"\n",
    "    _dpath = f\"{str(_path).split('/', 6)[6]:<{60}} | \"\n",
    "\n",
    "    print(f\"{_idx}{_dshape}{_lshape}{_ddtype}{_dlabel1}{_dlabel2}{_dlabel3}{_dpath}{_ldtype}\")\n",
    "\n",
    "    if counter == _stop:\n",
    "        break\n",
    "    else:\n",
    "        counter = counter + 1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-17T11:46:01.158185Z",
     "start_time": "2024-06-17T11:46:01.123198Z"
    }
   },
   "id": "acc591d6dc60be1a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# CREATING A MODEL USING PYTORCH SEQUENIAL"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3cfce6c3c2d50c01"
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# Import torch\n",
    "import torch\n",
    "\n",
    "# Setup device agnostic code\n",
    "#device agnostic code - automatically set what cpu\\gpu to use for best performance\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Setup random seed\n",
    "#RANDOM_SEED = 42"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-17T11:48:34.170331Z",
     "start_time": "2024-06-17T11:48:34.152852Z"
    }
   },
   "id": "2ad523a37aaaac70"
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchmetrics import Accuracy"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-17T11:48:34.814928Z",
     "start_time": "2024-06-17T11:48:34.813660Z"
    }
   },
   "id": "e073483ccd58375e"
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "outputs": [],
   "source": [
    "\n",
    "class PiczakRec(nn.Module):\n",
    "    def __init__(self,inputSize,outputSize,hiddenNeurons,filtersize,poolingsize,padsize,stridesize,flattensize):\n",
    "        super().__init__()\n",
    "\n",
    "        self.nnBlock1 = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=inputSize,out_channels=80,kernel_size=(57,6),padding=0),\n",
    "                nn.ReLU(),\n",
    "                #nn.MaxPool2d(kernel_size=(4,3),stride=(1,3)),\n",
    "        )    \n",
    "        \n",
    "        self.nnBlock2 = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=80,out_channels=80,kernel_size=(1,3),padding=0,stride = 1),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(kernel_size=(1,3),stride=(1,3))\n",
    "        )    \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=70720,out_features=500),\n",
    "            #nn.Linear(in_features=5000,out_features=5000),\n",
    "            nn.Linear(in_features=500,out_features=50)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.nnBlock1(x)\n",
    "        x = self.nnBlock2(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "            "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-17T11:48:34.823366Z",
     "start_time": "2024-06-17T11:48:34.817700Z"
    }
   },
   "id": "d1103327ceb4f064"
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "outputs": [],
   "source": [
    "inputSize=3#how many color channels, in my case 1\n",
    "outputSize=50\n",
    "hiddenNeurons=1\n",
    "filtersize=3\n",
    "poolingsize=2\n",
    "padsize=0\n",
    "stridesize=1\n",
    "flattensize=3528\n",
    "model = PiczakRec(inputSize,outputSize,hiddenNeurons,filtersize,poolingsize,padsize,stridesize,flattensize)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-17T11:48:34.925634Z",
     "start_time": "2024-06-17T11:48:34.820811Z"
    }
   },
   "id": "4edfb44bcd12e35a"
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "outputs": [],
   "source": [
    "#model.state_dict()\n",
    "#next(model.modules())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-17T11:48:34.934261Z",
     "start_time": "2024-06-17T11:48:34.925813Z"
    }
   },
   "id": "6cbfda5aa4826fa8"
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (80x884 and 70720x500)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[199], line 4\u001B[0m\n\u001B[1;32m      2\u001B[0m coeff,y \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mnext\u001B[39m(\u001B[38;5;28miter\u001B[39m(test_dataloader))\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mnumel(torch\u001B[38;5;241m.\u001B[39mtensor(coeff\u001B[38;5;241m.\u001B[39mshape)) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m4\u001B[39m:\n\u001B[0;32m----> 4\u001B[0m     model_pred_logits \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcoeff\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39msqueeze(dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m) \u001B[38;5;66;03m# make sure image is right shape + on right device\u001B[39;00m\n\u001B[1;32m      5\u001B[0m     model_pred_probs \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39msoftmax(model_pred_logits, dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m      6\u001B[0m     model_pred_label \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39margmax(model_pred_probs, dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "Cell \u001B[0;32mIn[196], line 26\u001B[0m, in \u001B[0;36mPiczakRec.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m     24\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnnBlock1(x)\n\u001B[1;32m     25\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnnBlock2(x)\n\u001B[0;32m---> 26\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mclassifier\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     27\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m x\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/container.py:215\u001B[0m, in \u001B[0;36mSequential.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    213\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[1;32m    214\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[0;32m--> 215\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    216\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/linear.py:114\u001B[0m, in \u001B[0;36mLinear.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m--> 114\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: mat1 and mat2 shapes cannot be multiplied (80x884 and 70720x500)"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "coeff,y = next(iter(test_dataloader))\n",
    "if torch.numel(torch.tensor(coeff.shape)) == 4:\n",
    "    model_pred_logits = model(coeff[0]).squeeze(dim=0) # make sure image is right shape + on right device\n",
    "    model_pred_probs = torch.softmax(model_pred_logits, dim=1)\n",
    "    model_pred_label = torch.argmax(model_pred_probs, dim=1)\n",
    "else:\n",
    "    model_pred_logits = model(coeff).squeeze(dim=0) # make sure image is right shape + on right device\n",
    "    model_pred_probs = torch.softmax(model_pred_logits, dim=1)\n",
    "    model_pred_label = torch.argmax(model_pred_probs, dim=1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-17T11:48:34.987914Z",
     "start_time": "2024-06-17T11:48:34.929678Z"
    }
   },
   "id": "d684de14845daf5e"
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([20, 3, 498, 13])"
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeff.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-17T11:48:35.600740Z",
     "start_time": "2024-06-17T11:48:35.597923Z"
    }
   },
   "id": "722b6f04c9807c15"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# THIS TO TO CALCULATE SIZES - OUTPUT OF LAYERS"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b578d49407909372"
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N\tC\tH\tW\t\n",
      "1\t80\t442\t8\t\n"
     ]
    }
   ],
   "source": [
    "from torchshape import tensorshape\n",
    "\n",
    "op = nn.Conv2d(in_channels=1,out_channels=80,kernel_size=(57,6),padding=0)\n",
    "outshape = tensorshape(op, in_shape = (1,1,498,13))\n",
    "print(f\"N\\tC\\tH\\tW\\t\");print(f\"{outshape[0]}\\t{outshape[1]}\\t{outshape[2]}\\t{outshape[3]}\\t\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-17T11:48:35.616526Z",
     "start_time": "2024-06-17T11:48:35.601284Z"
    }
   },
   "id": "dd6f0a34ff080783"
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N\tC\tH\tW\t\n",
      "1\t80\t439\t2\t\n"
     ]
    }
   ],
   "source": [
    "op1 = nn.MaxPool2d(kernel_size=(4,3),stride=(1,3))\n",
    "outshape = tensorshape(op=op1, in_shape = outshape)\n",
    "print(f\"N\\tC\\tH\\tW\\t\"); print(f\"{outshape[0]}\\t{outshape[1]}\\t{outshape[2]}\\t{outshape[3]}\\t\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-17T11:48:35.620564Z",
     "start_time": "2024-06-17T11:48:35.616303Z"
    }
   },
   "id": "e006ca0393e18609"
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N\tC\tH\tW\t\n",
      "1\t80\t439\t0\t\n"
     ]
    }
   ],
   "source": [
    "op = nn.Conv2d(in_channels=80,out_channels=80,kernel_size=(1,3),padding=0,stride = 1)\n",
    "outshape = tensorshape(op, in_shape = outshape)\n",
    "print(f\"N\\tC\\tH\\tW\\t\");print(f\"{outshape[0]}\\t{outshape[1]}\\t{outshape[2]}\\t{outshape[3]}\\t\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-17T11:48:36.237779Z",
     "start_time": "2024-06-17T11:48:36.235318Z"
    }
   },
   "id": "30e25a7a93b1fbab"
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N\tC\tH\tW\t\n",
      "1\t80\t439\t0\t\n"
     ]
    }
   ],
   "source": [
    "op1 = nn.MaxPool2d(kernel_size=(1,3),stride=(1,3))\n",
    "outshape = tensorshape(op=op1, in_shape = outshape)\n",
    "print(f\"N\\tC\\tH\\tW\\t\");print(f\"{outshape[0]}\\t{outshape[1]}\\t{outshape[2]}\\t{outshape[3]}\\t\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-17T11:48:36.245827Z",
     "start_time": "2024-06-17T11:48:36.238380Z"
    }
   },
   "id": "f7f145b97d710c07"
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H\tW\t\n",
      "1\t439\n"
     ]
    }
   ],
   "source": [
    "op2 = nn.Flatten()\n",
    "outshape = tensorshape(op=op2, in_shape = (1,1,439,1))\n",
    "print(f\"H\\tW\\t\");print(f\"{outshape[0]}\\t{outshape[1]}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-17T11:48:36.245964Z",
     "start_time": "2024-06-17T11:48:36.241355Z"
    }
   },
   "id": "1b52ee6b315e83a0"
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-17T11:48:36.842494Z",
     "start_time": "2024-06-17T11:48:36.839211Z"
    }
   },
   "id": "768f2c8af611ad81"
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-17T11:48:36.845066Z",
     "start_time": "2024-06-17T11:48:36.841767Z"
    }
   },
   "id": "cca600b7195bad57"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# INIT TENSORBOARD & SETUP\n",
    "Dashboard: [http://localhost:6006](http://localhost:6006)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b790c99c63949a3e"
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": "Launching TensorBoard..."
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch.utils.tensorboard\n",
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard\n",
    "# Stand Tensorboard\n",
    "%tensorboard --logdir=runs --reload_multifile True"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-17T11:48:38.520584Z",
     "start_time": "2024-06-17T11:48:37.472502Z"
    }
   },
   "id": "a7e9d44c10649ec4"
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "outputs": [],
   "source": [
    "#Create a SummyWriter which is LOG FILE DATABASE for our model\n",
    "#CHANGE THE NAME BASED ON THE MODEL WE USE - DONT FORGET\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "# default `log_dir` is \"runs\" - we'll be more specific here\n",
    "#_MODEL_NAME_ = \"model1_test_trash\"\n",
    "#writer = SummaryWriter(\"runs/\" + _MODEL_NAME_)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-17T11:48:38.520745Z",
     "start_time": "2024-06-17T11:48:38.515843Z"
    }
   },
   "id": "24424be8f3c6f260"
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-17T11:48:38.520794Z",
     "start_time": "2024-06-17T11:48:38.518039Z"
    }
   },
   "id": "cc9b68e40e95d5e9"
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/50 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e267b3f283f84cdf84ad7d01f4e897a4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/70 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "07755c25ce224812a52586dd77b30a51"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Loss: 9.617 | Test loss: 3.841 | Train Acc: 2.0714282989501953 | Test Acc: 2.333333730697632\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/70 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "90bf4de4ae40466e96b158edc7119846"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Loss: 3.814 | Test loss: 3.782 | Train Acc: 3.785712957382202 | Test Acc: 1.5000001192092896\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/70 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4af47516c0fe486da043656e47068d50"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 | Loss: 3.704 | Test loss: 3.730 | Train Acc: 7.142857551574707 | Test Acc: 2.000000238418579\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/70 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "104f611f94e64e0f956c7d99adfe6eb7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 | Loss: 3.515 | Test loss: 3.680 | Train Acc: 10.28571605682373 | Test Acc: 2.500000476837158\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/70 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "69ecf4a8e4c7473485ef11474640511d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 | Loss: 3.341 | Test loss: 3.623 | Train Acc: 13.071430206298828 | Test Acc: 2.000000238418579\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/70 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f9ce943386084570b2409e833a2d74d5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 | Loss: 3.184 | Test loss: 3.620 | Train Acc: 16.85714340209961 | Test Acc: 2.333333730697632\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/70 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "543a2d0aac144a96819d305471e093cf"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 | Loss: 3.076 | Test loss: 3.615 | Train Acc: 18.78571319580078 | Test Acc: 1.8333334922790527\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/70 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ffc59ab47bd641b29b9b929668699f3a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 | Loss: 2.954 | Test loss: 3.638 | Train Acc: 22.714284896850586 | Test Acc: 3.000000238418579\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/70 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d2c465030ef244e08212deaefb6e69cc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 | Loss: 2.843 | Test loss: 3.594 | Train Acc: 24.71428871154785 | Test Acc: 3.000000476837158\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/70 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c4e23bee3411427e869415acfe0c8197"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 | Loss: 2.740 | Test loss: 3.572 | Train Acc: 27.5 | Test Acc: 3.8333334922790527\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/70 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2ea4f9a080d14ac6859ad24f2197eb04"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 | Loss: 2.661 | Test loss: 3.566 | Train Acc: 30.928569793701172 | Test Acc: 2.8333334922790527\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/70 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9fa5659e3c17442f83c51bf47ca6a943"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11 | Loss: 2.595 | Test loss: 3.578 | Train Acc: 32.28571701049805 | Test Acc: 2.6666669845581055\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/70 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "73784061050d433ebf3e9a7d19a2bea6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12 | Loss: 2.531 | Test loss: 3.469 | Train Acc: 35.000003814697266 | Test Acc: 1.3333334922790527\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/70 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a7d7cb587d6347268152569951a36b4d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13 | Loss: 2.461 | Test loss: 3.555 | Train Acc: 35.85713577270508 | Test Acc: 5.0\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/70 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e7dc9d6233af46cd84395d7e04104f6a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14 | Loss: 2.402 | Test loss: 3.548 | Train Acc: 37.42857360839844 | Test Acc: 2.500000238418579\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/70 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9b69ea9b07f94e41b2e1edb855887fb0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15 | Loss: 2.349 | Test loss: 3.459 | Train Acc: 37.92857360839844 | Test Acc: 3.1666669845581055\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/70 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b8dd65741e5043eb984fc6e9c7ac2da3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16 | Loss: 2.290 | Test loss: 3.428 | Train Acc: 39.642860412597656 | Test Acc: 3.0\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/70 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "42bee8078379401f8861efbba821fa2f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17 | Loss: 2.259 | Test loss: 3.344 | Train Acc: 40.071434020996094 | Test Acc: 2.833333730697632\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/70 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9d6799179d5f47489ea4493559481b88"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18 | Loss: 2.184 | Test loss: 3.474 | Train Acc: 41.28571319580078 | Test Acc: 4.499999523162842\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/70 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9216a3b270ec4ada847049a2fd6b49d0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19 | Loss: 2.163 | Test loss: 3.450 | Train Acc: 42.71428680419922 | Test Acc: 4.666666507720947\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/70 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "df02cd4c0ad449778363f9e4b41f35f7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20 | Loss: 2.128 | Test loss: 3.365 | Train Acc: 41.85714340209961 | Test Acc: 2.6666669845581055\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/70 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d7ea3b39a2214839afdc538a6d6575ab"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[208], line 50\u001B[0m\n\u001B[1;32m     48\u001B[0m train_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m loss\n\u001B[1;32m     49\u001B[0m \u001B[38;5;66;03m#Note 2.1 Cumulatively add up the ACCURACY per epoch\u001B[39;00m\n\u001B[0;32m---> 50\u001B[0m train_acc \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[43macc_func\u001B[49m\u001B[43m(\u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_hat\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m#this slows down the runtime?\u001B[39;00m\n\u001B[1;32m     52\u001B[0m \u001B[38;5;66;03m#Note 3. Optimizer zero grad - reset gradients\u001B[39;00m\n\u001B[1;32m     53\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/torchmetrics/metric.py:304\u001B[0m, in \u001B[0;36mMetric.forward\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    302\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_cache \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_full_state_update(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    303\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 304\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_cache \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_forward_reduce_state_update\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    306\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_cache\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/torchmetrics/metric.py:373\u001B[0m, in \u001B[0;36mMetric._forward_reduce_state_update\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    370\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_enable_grad \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m  \u001B[38;5;66;03m# allow grads for batch computation\u001B[39;00m\n\u001B[1;32m    372\u001B[0m \u001B[38;5;66;03m# calculate batch state and compute batch value\u001B[39;00m\n\u001B[0;32m--> 373\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mupdate\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    374\u001B[0m batch_val \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcompute()\n\u001B[1;32m    376\u001B[0m \u001B[38;5;66;03m# reduce batch and global state\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/torchmetrics/metric.py:466\u001B[0m, in \u001B[0;36mMetric._wrap_update.<locals>.wrapped_func\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    464\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mset_grad_enabled(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_enable_grad):\n\u001B[1;32m    465\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 466\u001B[0m         \u001B[43mupdate\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    467\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[1;32m    468\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExpected all tensors to be on\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mstr\u001B[39m(err):\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/torchmetrics/classification/stat_scores.py:333\u001B[0m, in \u001B[0;36mMulticlassStatScores.update\u001B[0;34m(self, preds, target)\u001B[0m\n\u001B[1;32m    331\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Update state with predictions and targets.\"\"\"\u001B[39;00m\n\u001B[1;32m    332\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mvalidate_args:\n\u001B[0;32m--> 333\u001B[0m     \u001B[43m_multiclass_stat_scores_tensor_validation\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    334\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpreds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnum_classes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmultidim_average\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mignore_index\u001B[49m\n\u001B[1;32m    335\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    336\u001B[0m preds, target \u001B[38;5;241m=\u001B[39m _multiclass_stat_scores_format(preds, target, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtop_k)\n\u001B[1;32m    337\u001B[0m tp, fp, tn, fn \u001B[38;5;241m=\u001B[39m _multiclass_stat_scores_update(\n\u001B[1;32m    338\u001B[0m     preds, target, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_classes, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtop_k, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maverage, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmultidim_average, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mignore_index\n\u001B[1;32m    339\u001B[0m )\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/torchmetrics/functional/classification/stat_scores.py:309\u001B[0m, in \u001B[0;36m_multiclass_stat_scores_tensor_validation\u001B[0;34m(preds, target, num_classes, multidim_average, ignore_index)\u001B[0m\n\u001B[1;32m    307\u001B[0m check_value \u001B[38;5;241m=\u001B[39m num_classes \u001B[38;5;28;01mif\u001B[39;00m ignore_index \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m num_classes \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    308\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m t, name \u001B[38;5;129;01min\u001B[39;00m ((target, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtarget\u001B[39m\u001B[38;5;124m\"\u001B[39m),) \u001B[38;5;241m+\u001B[39m ((preds, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpreds\u001B[39m\u001B[38;5;124m\"\u001B[39m),) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m preds\u001B[38;5;241m.\u001B[39mis_floating_point() \u001B[38;5;28;01melse\u001B[39;00m ():  \u001B[38;5;66;03m# noqa: RUF005\u001B[39;00m\n\u001B[0;32m--> 309\u001B[0m     num_unique_values \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43munique\u001B[49m\u001B[43m(\u001B[49m\u001B[43mt\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m    310\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m num_unique_values \u001B[38;5;241m>\u001B[39m check_value:\n\u001B[1;32m    311\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[1;32m    312\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDetected more unique values in `\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m` than expected. Expected only \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mcheck_value\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m but found\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    313\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnum_unique_values\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m in `target`.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    314\u001B[0m         )\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/torch/_jit_internal.py:488\u001B[0m, in \u001B[0;36mboolean_dispatch.<locals>.fn\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    486\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m if_true(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    487\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 488\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mif_false\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/torch/_jit_internal.py:488\u001B[0m, in \u001B[0;36mboolean_dispatch.<locals>.fn\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    486\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m if_true(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    487\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 488\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mif_false\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/torch/functional.py:976\u001B[0m, in \u001B[0;36m_return_output\u001B[0;34m(input, sorted, return_inverse, return_counts, dim)\u001B[0m\n\u001B[1;32m    973\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28minput\u001B[39m):\n\u001B[1;32m    974\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _unique_impl(\u001B[38;5;28minput\u001B[39m, \u001B[38;5;28msorted\u001B[39m, return_inverse, return_counts, dim)\n\u001B[0;32m--> 976\u001B[0m output, _, _ \u001B[38;5;241m=\u001B[39m \u001B[43m_unique_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43msorted\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreturn_inverse\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreturn_counts\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdim\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    977\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m output\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/torch/functional.py:890\u001B[0m, in \u001B[0;36m_unique_impl\u001B[0;34m(input, sorted, return_inverse, return_counts, dim)\u001B[0m\n\u001B[1;32m    882\u001B[0m     output, inverse_indices, counts \u001B[38;5;241m=\u001B[39m _VF\u001B[38;5;241m.\u001B[39munique_dim(\n\u001B[1;32m    883\u001B[0m         \u001B[38;5;28minput\u001B[39m,\n\u001B[1;32m    884\u001B[0m         dim,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    887\u001B[0m         return_counts\u001B[38;5;241m=\u001B[39mreturn_counts,\n\u001B[1;32m    888\u001B[0m     )\n\u001B[1;32m    889\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 890\u001B[0m     output, inverse_indices, counts \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_unique2\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    891\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    892\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43msorted\u001B[39;49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43msorted\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    893\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_inverse\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_inverse\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    894\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_counts\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_counts\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    895\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    896\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m output, inverse_indices, counts\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# NOTE: SETUP METRICS USING TORCH LIBRARY - NOT SURE IF THIS MAKES IT EASIER OR NOT \n",
    "acc_func = Accuracy(task=\"multiclass\", num_classes=50).to(device)\n",
    "\n",
    "# NOTE: SETUP TQDM TO SHOW A PROGRESS BAR\n",
    "from tqdm.auto import tqdm \n",
    "\n",
    "#Summary 1: Create Model\n",
    "model = model.to(device)\n",
    "\n",
    "#Summary 2: Create Loss Function & Optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "#Summary 3: Setup SummaryWriter\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "_MODEL_NAME_ = \"model50_test_trash\" #NOTE: CHANGE ME\n",
    "writer = SummaryWriter(\"runs/\" + _MODEL_NAME_)\n",
    "\n",
    "### Training loop\n",
    "epochs = 50\n",
    "for epoch in tqdm(range(epochs)):\n",
    "\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    \n",
    "    #ii TRAINING loop\n",
    "    for batch, (X, y) in enumerate(tqdm(train_dataloader)):\n",
    "        #Note 0. Turn On Training Mode\n",
    "        model.train()\n",
    "        #Note 0.1. Put data on CPU\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        #Note 0.2. Check That Data has values - #ERROR This can be deleted quite honestly\n",
    "        if torch.isnan(X).any() or torch.isinf(X).any():\n",
    "            print(\"Data contains NaN or Inf values.\")\n",
    "\n",
    "        #Note 1. Forward pass\n",
    "        logits = model(X)\n",
    "        #Note 1.1 Convert Raw Logit Outputs to y predictions\n",
    "        y_pred = torch.softmax(logits, dim = 1)  #;print(y_pred.shape)\n",
    "        #Note 1.2 Convert y predictions to labels as y hat\n",
    "        y_hat = torch.argmax(y_pred, dim = 1)  #;print(y_hat.shape);print(y_hat)\n",
    "\n",
    "        #Note 2. Loss calculation\n",
    "        loss = loss_fn(logits, y)\n",
    "        #Note 2.1 Cumulatively add up the LOSS per epoch\n",
    "        train_loss += loss\n",
    "        #Note 2.1 Cumulatively add up the ACCURACY per epoch\n",
    "        train_acc += acc_func(y, y_hat)  #this slows down the runtime?\n",
    "\n",
    "        #Note 3. Optimizer zero grad - reset gradients\n",
    "        optimizer.zero_grad()\n",
    "        #Note 4. Loss backward - Backward propagation\n",
    "        loss.backward()\n",
    "        #Note 5. Step the optimizer - optimize\\upgade weight\\biases\\paramters of kernels\n",
    "        optimizer.step()\n",
    "\n",
    "    #Summary: Adjust TRAIN LOSS & ACCURACY for number of batches \n",
    "    #SUMMARY: Meaning -> Divide total TRAIN LOSS & ACC by length of TRAIN DATALOADER = (average loss per batch per epoch)\n",
    "    train_loss /= len(train_dataloader)\n",
    "    train_acc /= len(train_dataloader)\n",
    "\n",
    "    #ii TESTING loop\n",
    "    #Note 0. init Metric Params\n",
    "    test_loss = 0\n",
    "    test_acc = 0\n",
    "    \n",
    "    #Note 1. Put model in eval mode \n",
    "    model.eval()\n",
    "\n",
    "    #Note 1.1 Turn on inference mode - best way currently to do evaluation\n",
    "    with torch.inference_mode():\n",
    "        for batch, (X_test, y_test) in enumerate(test_dataloader):\n",
    "            #Note 2. Make sure test data on CPU\n",
    "            X_test, y_test = X_test.to(device), y_test.to(device)\n",
    "            #Note 3. Forward Pass\n",
    "            logits = model(X_test)\n",
    "            #Note 3.1 Convert Raw Logits (outputs) to y predictions\n",
    "            y_pred = torch.softmax(logits, dim = 1)  #;print(y_pred.shape)\n",
    "            #Note 3.2 Convert y predictions to y labels as y hat\n",
    "            y_hat = torch.argmax(y_pred, dim = 1)\n",
    "\n",
    "            \n",
    "            \n",
    "            #Note 4. Calculate The Loss\n",
    "            loss = loss_fn(logits, y_test)\n",
    "            #Note 4.1 Cumulatively add up the LOSS per epoch (all batches)\n",
    "            test_loss += loss\n",
    "            #Note 4.2 Cumulatively add up the ACCURACY per epoch (all batches)\n",
    "            test_acc += acc_func(y, y_hat)  #this slows down the runtime\n",
    "        \n",
    "        #Summary: Adjust TEST LOSS & ACCURACY for number of batches \n",
    "        #SUMMARY: Meaning -> Divide total TEST LOSS & ACC by length of TEST DATALOADER = (average loss per batch per epoch)\n",
    "        test_loss /= len(test_dataloader)\n",
    "        test_acc /= len(test_dataloader)\n",
    "\n",
    "    # Print out what's happening\n",
    "    print(f\"Epoch: {epoch} | Loss: {train_loss:.3f} | Test loss: {test_loss:.3f} | Train Acc: {train_acc * 100} | Test Acc: {test_acc * 100}\")\n",
    "    \n",
    "    #Note: Tensorboard Logging\n",
    "    #writer.add_scalar(\"Loss/Train\", train_loss, epoch)\n",
    "    #writer.add_scalar(\"Loss/Test\", test_loss, epoch)\n",
    "    #writer.add_scalar(\"Accuracy/Train\", train_acc*100, epoch)\n",
    "    #writer.add_scalar(tag = \"Accuracy/Test\", scalar_value = test_acc*100,global_step =  epoch)\n",
    "    \n",
    "    writer.add_scalars(\"Loss\",{'Train':train_loss},epoch)\n",
    "    writer.add_scalars(\"Loss\",{'Test':test_loss},epoch)\n",
    "\n",
    "    \n",
    "    writer.add_scalars(\"Accuracy\",{'Train':train_acc*100},epoch)\n",
    "    writer.add_scalars(\"Accuracy\",{'Test':test_acc*100},epoch)\n",
    "\n",
    "    writer.add_scalars(\"Train Loss/Accuracy\",{'Loss':train_loss},epoch)\n",
    "    writer.add_scalars(\"Train Loss/Accuracy\",{'Accuracy':train_acc*100},epoch)\n",
    "\n",
    "    writer.add_scalars(\"Test Loss/Accuracy\",{'Loss':test_loss},epoch)\n",
    "    writer.add_scalars(\"Test Loss/Accuracy\",{'Accuracy':test_acc*100},epoch)\n",
    "\n",
    "\n",
    "    #Call flush() method to make sure that all pending events have been written to disk.\n",
    "    writer.flush()\n",
    "\n",
    "writer.close()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-17T11:49:50.302065Z",
     "start_time": "2024-06-17T11:48:39.192854Z"
    }
   },
   "id": "6e03ff4858895a60"
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "outputs": [],
   "source": [
    "#Add Model Structure To TensorBoard\n",
    "coeff,y = next(iter(test_dataloader))\n",
    "writer.add_graph(model, coeff.to(device))\n",
    "#writer.close()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-17T11:49:52.448802Z",
     "start_time": "2024-06-17T11:49:52.296304Z"
    }
   },
   "id": "24b47ab974fa72e4"
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "outputs": [
    {
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 11.0.0 (0)\n -->\n<!-- Title: MLP Pages: 1 -->\n<svg width=\"220pt\" height=\"772pt\"\n viewBox=\"0.00 0.00 220.00 771.75\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 767.75)\">\n<title>MLP</title>\n<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-767.75 216,-767.75 216,4 -4,4\"/>\n<g id=\"clust1\" class=\"cluster\">\n<title>cluster_2</title>\n<polygon fill=\"none\" stroke=\"black\" stroke-dasharray=\"5,2\" points=\"15,-565 15,-723.25 197,-723.25 197,-565 15,-565\"/>\n<text text-anchor=\"middle\" x=\"47.75\" y=\"-707.85\" font-family=\"Times,serif\" font-size=\"12.00\">Sequential</text>\n</g>\n<g id=\"clust2\" class=\"cluster\">\n<title>cluster_3</title>\n<polygon fill=\"none\" stroke=\"black\" stroke-dasharray=\"5,2\" points=\"8,-320.75 8,-557 204,-557 204,-320.75 8,-320.75\"/>\n<text text-anchor=\"middle\" x=\"40.75\" y=\"-541.6\" font-family=\"Times,serif\" font-size=\"12.00\">Sequential</text>\n</g>\n<g id=\"clust3\" class=\"cluster\">\n<title>cluster_4</title>\n<polygon fill=\"none\" stroke=\"black\" stroke-dasharray=\"5,2\" points=\"16,-8 16,-312.75 196,-312.75 196,-8 16,-8\"/>\n<text text-anchor=\"middle\" x=\"48.75\" y=\"-297.35\" font-family=\"Times,serif\" font-size=\"12.00\">Sequential</text>\n</g>\n<!-- 0 -->\n<g id=\"node1\" class=\"node\">\n<title>0</title>\n<polygon fill=\"lightyellow\" stroke=\"none\" points=\"174.5,-763.75 37.5,-763.75 37.5,-731.25 174.5,-731.25 174.5,-763.75\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"37.5,-731.25 37.5,-763.75 98.5,-763.75 98.5,-731.25 37.5,-731.25\"/>\n<text text-anchor=\"start\" x=\"42.5\" y=\"-749.25\" font-family=\"Linux libertine\" font-size=\"10.00\">input&#45;tensor</text>\n<text text-anchor=\"start\" x=\"51.88\" y=\"-738\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:0</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"98.5,-731.25 98.5,-763.75 174.5,-763.75 174.5,-731.25 98.5,-731.25\"/>\n<text text-anchor=\"start\" x=\"103.5\" y=\"-743.62\" font-family=\"Linux libertine\" font-size=\"10.00\">(20, 3, 498, 13)</text>\n</g>\n<!-- 1 -->\n<g id=\"node2\" class=\"node\">\n<title>1</title>\n<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"188.5,-693 23.5,-693 23.5,-651 188.5,-651 188.5,-693\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"23.5,-651 23.5,-693 66.5,-693 66.5,-651 23.5,-651\"/>\n<text text-anchor=\"start\" x=\"28.12\" y=\"-673.75\" font-family=\"Linux libertine\" font-size=\"10.00\">Conv2d</text>\n<text text-anchor=\"start\" x=\"28.88\" y=\"-662.5\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:2</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"66.5,-672 66.5,-693 109.5,-693 109.5,-672 66.5,-672\"/>\n<text text-anchor=\"start\" x=\"76\" y=\"-678.5\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"109.5,-672 109.5,-693 188.5,-693 188.5,-672 109.5,-672\"/>\n<text text-anchor=\"start\" x=\"114.5\" y=\"-678.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(20, 3, 498, 13) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"66.5,-651 66.5,-672 109.5,-672 109.5,-651 66.5,-651\"/>\n<text text-anchor=\"start\" x=\"71.5\" y=\"-657.5\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"109.5,-651 109.5,-672 188.5,-672 188.5,-651 109.5,-651\"/>\n<text text-anchor=\"start\" x=\"114.5\" y=\"-657.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(20, 80, 442, 8) </text>\n</g>\n<!-- 0&#45;&gt;1 -->\n<g id=\"edge1\" class=\"edge\">\n<title>0&#45;&gt;1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M106,-731.27C106,-723.47 106,-713.66 106,-704.33\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"109.5,-704.47 106,-694.47 102.5,-704.47 109.5,-704.47\"/>\n</g>\n<!-- 2 -->\n<g id=\"node3\" class=\"node\">\n<title>2</title>\n<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"188,-615 24,-615 24,-573 188,-573 188,-615\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"24,-573 24,-615 66,-615 66,-573 24,-573\"/>\n<text text-anchor=\"start\" x=\"32.25\" y=\"-595.75\" font-family=\"Linux libertine\" font-size=\"10.00\">ReLU</text>\n<text text-anchor=\"start\" x=\"28.88\" y=\"-584.5\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:2</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"66,-594 66,-615 109,-615 109,-594 66,-594\"/>\n<text text-anchor=\"start\" x=\"75.5\" y=\"-600.5\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"109,-594 109,-615 188,-615 188,-594 109,-594\"/>\n<text text-anchor=\"start\" x=\"114\" y=\"-600.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(20, 80, 442, 8) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"66,-573 66,-594 109,-594 109,-573 66,-573\"/>\n<text text-anchor=\"start\" x=\"71\" y=\"-579.5\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"109,-573 109,-594 188,-594 188,-573 109,-573\"/>\n<text text-anchor=\"start\" x=\"114\" y=\"-579.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(20, 80, 442, 8) </text>\n</g>\n<!-- 1&#45;&gt;2 -->\n<g id=\"edge2\" class=\"edge\">\n<title>1&#45;&gt;2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M106,-651.03C106,-643.44 106,-634.6 106,-626.21\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"109.5,-626.35 106,-616.35 102.5,-626.35 109.5,-626.35\"/>\n</g>\n<!-- 3 -->\n<g id=\"node4\" class=\"node\">\n<title>3</title>\n<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"188.5,-526.75 23.5,-526.75 23.5,-484.75 188.5,-484.75 188.5,-526.75\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"23.5,-484.75 23.5,-526.75 66.5,-526.75 66.5,-484.75 23.5,-484.75\"/>\n<text text-anchor=\"start\" x=\"28.12\" y=\"-507.5\" font-family=\"Linux libertine\" font-size=\"10.00\">Conv2d</text>\n<text text-anchor=\"start\" x=\"28.88\" y=\"-496.25\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:2</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"66.5,-505.75 66.5,-526.75 109.5,-526.75 109.5,-505.75 66.5,-505.75\"/>\n<text text-anchor=\"start\" x=\"76\" y=\"-512.25\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"109.5,-505.75 109.5,-526.75 188.5,-526.75 188.5,-505.75 109.5,-505.75\"/>\n<text text-anchor=\"start\" x=\"114.5\" y=\"-512.25\" font-family=\"Linux libertine\" font-size=\"10.00\">(20, 80, 442, 8) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"66.5,-484.75 66.5,-505.75 109.5,-505.75 109.5,-484.75 66.5,-484.75\"/>\n<text text-anchor=\"start\" x=\"71.5\" y=\"-491.25\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"109.5,-484.75 109.5,-505.75 188.5,-505.75 188.5,-484.75 109.5,-484.75\"/>\n<text text-anchor=\"start\" x=\"114.5\" y=\"-491.25\" font-family=\"Linux libertine\" font-size=\"10.00\">(20, 80, 442, 6) </text>\n</g>\n<!-- 2&#45;&gt;3 -->\n<g id=\"edge3\" class=\"edge\">\n<title>2&#45;&gt;3</title>\n<path fill=\"none\" stroke=\"black\" d=\"M106,-573.43C106,-562.92 106,-549.71 106,-537.83\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"109.5,-538.06 106,-528.06 102.5,-538.06 109.5,-538.06\"/>\n</g>\n<!-- 4 -->\n<g id=\"node5\" class=\"node\">\n<title>4</title>\n<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"188,-448.75 24,-448.75 24,-406.75 188,-406.75 188,-448.75\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"24,-406.75 24,-448.75 66,-448.75 66,-406.75 24,-406.75\"/>\n<text text-anchor=\"start\" x=\"32.25\" y=\"-429.5\" font-family=\"Linux libertine\" font-size=\"10.00\">ReLU</text>\n<text text-anchor=\"start\" x=\"28.88\" y=\"-418.25\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:2</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"66,-427.75 66,-448.75 109,-448.75 109,-427.75 66,-427.75\"/>\n<text text-anchor=\"start\" x=\"75.5\" y=\"-434.25\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"109,-427.75 109,-448.75 188,-448.75 188,-427.75 109,-427.75\"/>\n<text text-anchor=\"start\" x=\"114\" y=\"-434.25\" font-family=\"Linux libertine\" font-size=\"10.00\">(20, 80, 442, 6) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"66,-406.75 66,-427.75 109,-427.75 109,-406.75 66,-406.75\"/>\n<text text-anchor=\"start\" x=\"71\" y=\"-413.25\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"109,-406.75 109,-427.75 188,-427.75 188,-406.75 109,-406.75\"/>\n<text text-anchor=\"start\" x=\"114\" y=\"-413.25\" font-family=\"Linux libertine\" font-size=\"10.00\">(20, 80, 442, 6) </text>\n</g>\n<!-- 3&#45;&gt;4 -->\n<g id=\"edge4\" class=\"edge\">\n<title>3&#45;&gt;4</title>\n<path fill=\"none\" stroke=\"black\" d=\"M106,-484.78C106,-477.19 106,-468.35 106,-459.96\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"109.5,-460.1 106,-450.1 102.5,-460.1 109.5,-460.1\"/>\n</g>\n<!-- 5 -->\n<g id=\"node6\" class=\"node\">\n<title>5</title>\n<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"196,-370.75 16,-370.75 16,-328.75 196,-328.75 196,-370.75\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"16,-328.75 16,-370.75 74,-370.75 74,-328.75 16,-328.75\"/>\n<text text-anchor=\"start\" x=\"20.62\" y=\"-351.5\" font-family=\"Linux libertine\" font-size=\"10.00\">MaxPool2d</text>\n<text text-anchor=\"start\" x=\"28.88\" y=\"-340.25\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:2</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"74,-349.75 74,-370.75 117,-370.75 117,-349.75 74,-349.75\"/>\n<text text-anchor=\"start\" x=\"83.5\" y=\"-356.25\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"117,-349.75 117,-370.75 196,-370.75 196,-349.75 117,-349.75\"/>\n<text text-anchor=\"start\" x=\"122\" y=\"-356.25\" font-family=\"Linux libertine\" font-size=\"10.00\">(20, 80, 442, 6) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"74,-328.75 74,-349.75 117,-349.75 117,-328.75 74,-328.75\"/>\n<text text-anchor=\"start\" x=\"79\" y=\"-335.25\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"117,-328.75 117,-349.75 196,-349.75 196,-328.75 117,-328.75\"/>\n<text text-anchor=\"start\" x=\"122\" y=\"-335.25\" font-family=\"Linux libertine\" font-size=\"10.00\">(20, 80, 442, 2) </text>\n</g>\n<!-- 4&#45;&gt;5 -->\n<g id=\"edge5\" class=\"edge\">\n<title>4&#45;&gt;5</title>\n<path fill=\"none\" stroke=\"black\" d=\"M106,-406.78C106,-399.19 106,-390.35 106,-381.96\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"109.5,-382.1 106,-372.1 102.5,-382.1 109.5,-382.1\"/>\n</g>\n<!-- 6 -->\n<g id=\"node7\" class=\"node\">\n<title>6</title>\n<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"188,-282.5 24,-282.5 24,-240.5 188,-240.5 188,-282.5\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"24,-240.5 24,-282.5 66,-282.5 66,-240.5 24,-240.5\"/>\n<text text-anchor=\"start\" x=\"30\" y=\"-263.25\" font-family=\"Linux libertine\" font-size=\"10.00\">Flatten</text>\n<text text-anchor=\"start\" x=\"28.88\" y=\"-252\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:2</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"66,-261.5 66,-282.5 109,-282.5 109,-261.5 66,-261.5\"/>\n<text text-anchor=\"start\" x=\"75.5\" y=\"-268\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"109,-261.5 109,-282.5 188,-282.5 188,-261.5 109,-261.5\"/>\n<text text-anchor=\"start\" x=\"114\" y=\"-268\" font-family=\"Linux libertine\" font-size=\"10.00\">(20, 80, 442, 2) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"66,-240.5 66,-261.5 109,-261.5 109,-240.5 66,-240.5\"/>\n<text text-anchor=\"start\" x=\"71\" y=\"-247\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"109,-240.5 109,-261.5 188,-261.5 188,-240.5 109,-240.5\"/>\n<text text-anchor=\"start\" x=\"122.62\" y=\"-247\" font-family=\"Linux libertine\" font-size=\"10.00\">(20, 70720) </text>\n</g>\n<!-- 5&#45;&gt;6 -->\n<g id=\"edge6\" class=\"edge\">\n<title>5&#45;&gt;6</title>\n<path fill=\"none\" stroke=\"black\" d=\"M106,-329.18C106,-318.67 106,-305.46 106,-293.58\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"109.5,-293.81 106,-283.81 102.5,-293.81 109.5,-293.81\"/>\n</g>\n<!-- 7 -->\n<g id=\"node8\" class=\"node\">\n<title>7</title>\n<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"179,-204.5 33,-204.5 33,-162.5 179,-162.5 179,-204.5\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"33,-162.5 33,-204.5 75,-204.5 75,-162.5 33,-162.5\"/>\n<text text-anchor=\"start\" x=\"40.88\" y=\"-185.25\" font-family=\"Linux libertine\" font-size=\"10.00\">Linear</text>\n<text text-anchor=\"start\" x=\"37.88\" y=\"-174\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:2</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"75,-183.5 75,-204.5 118,-204.5 118,-183.5 75,-183.5\"/>\n<text text-anchor=\"start\" x=\"84.5\" y=\"-190\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"118,-183.5 118,-204.5 179,-204.5 179,-183.5 118,-183.5\"/>\n<text text-anchor=\"start\" x=\"122.62\" y=\"-190\" font-family=\"Linux libertine\" font-size=\"10.00\">(20, 70720) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"75,-162.5 75,-183.5 118,-183.5 118,-162.5 75,-162.5\"/>\n<text text-anchor=\"start\" x=\"80\" y=\"-169\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"118,-162.5 118,-183.5 179,-183.5 179,-162.5 118,-162.5\"/>\n<text text-anchor=\"start\" x=\"127.88\" y=\"-169\" font-family=\"Linux libertine\" font-size=\"10.00\">(20, 500) </text>\n</g>\n<!-- 6&#45;&gt;7 -->\n<g id=\"edge7\" class=\"edge\">\n<title>6&#45;&gt;7</title>\n<path fill=\"none\" stroke=\"black\" d=\"M106,-240.53C106,-232.94 106,-224.1 106,-215.71\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"109.5,-215.85 106,-205.85 102.5,-215.85 109.5,-215.85\"/>\n</g>\n<!-- 8 -->\n<g id=\"node9\" class=\"node\">\n<title>8</title>\n<polygon fill=\"#c1ffc1\" stroke=\"none\" points=\"174,-126.5 38,-126.5 38,-84.5 174,-84.5 174,-126.5\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"38,-84.5 38,-126.5 80,-126.5 80,-84.5 38,-84.5\"/>\n<text text-anchor=\"start\" x=\"45.88\" y=\"-107.25\" font-family=\"Linux libertine\" font-size=\"10.00\">Linear</text>\n<text text-anchor=\"start\" x=\"42.88\" y=\"-96\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:2</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"80,-105.5 80,-126.5 123,-126.5 123,-105.5 80,-105.5\"/>\n<text text-anchor=\"start\" x=\"89.5\" y=\"-112\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"123,-105.5 123,-126.5 174,-126.5 174,-105.5 123,-105.5\"/>\n<text text-anchor=\"start\" x=\"127.88\" y=\"-112\" font-family=\"Linux libertine\" font-size=\"10.00\">(20, 500) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"80,-84.5 80,-105.5 123,-105.5 123,-84.5 80,-84.5\"/>\n<text text-anchor=\"start\" x=\"85\" y=\"-91\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"123,-84.5 123,-105.5 174,-105.5 174,-84.5 123,-84.5\"/>\n<text text-anchor=\"start\" x=\"130.5\" y=\"-91\" font-family=\"Linux libertine\" font-size=\"10.00\">(20, 50) </text>\n</g>\n<!-- 7&#45;&gt;8 -->\n<g id=\"edge8\" class=\"edge\">\n<title>7&#45;&gt;8</title>\n<path fill=\"none\" stroke=\"black\" d=\"M106,-162.53C106,-154.94 106,-146.1 106,-137.71\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"109.5,-137.85 106,-127.85 102.5,-137.85 109.5,-137.85\"/>\n</g>\n<!-- 9 -->\n<g id=\"node10\" class=\"node\">\n<title>9</title>\n<polygon fill=\"lightyellow\" stroke=\"none\" points=\"161,-48.5 51,-48.5 51,-16 161,-16 161,-48.5\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"51,-16 51,-48.5 118,-48.5 118,-16 51,-16\"/>\n<text text-anchor=\"start\" x=\"56\" y=\"-34\" font-family=\"Linux libertine\" font-size=\"10.00\">output&#45;tensor</text>\n<text text-anchor=\"start\" x=\"68.38\" y=\"-22.75\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:0</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"118,-16 118,-48.5 161,-48.5 161,-16 118,-16\"/>\n<text text-anchor=\"start\" x=\"123\" y=\"-28.38\" font-family=\"Linux libertine\" font-size=\"10.00\">(20, 50)</text>\n</g>\n<!-- 8&#45;&gt;9 -->\n<g id=\"edge9\" class=\"edge\">\n<title>8&#45;&gt;9</title>\n<path fill=\"none\" stroke=\"black\" d=\"M106,-84.65C106,-76.91 106,-67.91 106,-59.63\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"109.5,-59.76 106,-49.76 102.5,-59.76 109.5,-59.76\"/>\n</g>\n</g>\n</svg>\n",
      "text/plain": "<graphviz.graphs.Digraph at 0x31cd79490>"
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#Summary: Plot The Model Structure & Sizes\n",
    "from torchview import draw_graph\n",
    "viz_model = PiczakRec(3,0,0,0,0,0,0,0)\n",
    "N = 20;C = 3;H=498;W = 13\n",
    "input_data = torch.randn(N,C,H,W)\n",
    "model_graph = draw_graph(viz_model,input_data,expand_nested=True, roll=True,graph_name='MLP',hide_inner_tensors=True,hide_module_functions=True)\n",
    "model_graph.visual_graph"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-17T11:50:06.604304Z",
     "start_time": "2024-06-17T11:50:04.946452Z"
    }
   },
   "id": "721841eaa5742c15"
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "outputs": [
    {
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 11.0.0 (0)\n -->\n<!-- Title: MLP Pages: 1 -->\n<svg width=\"240pt\" height=\"938pt\"\n viewBox=\"0.00 0.00 240.00 937.75\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 933.75)\">\n<title>MLP</title>\n<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-933.75 236,-933.75 236,4 -4,4\"/>\n<g id=\"clust1\" class=\"cluster\">\n<title>cluster_2</title>\n<polygon fill=\"none\" stroke=\"black\" stroke-dasharray=\"5,2\" points=\"18,-682.5 18,-889.25 214,-889.25 214,-682.5 18,-682.5\"/>\n<text text-anchor=\"middle\" x=\"50.75\" y=\"-873.85\" font-family=\"Times,serif\" font-size=\"12.00\">Sequential</text>\n</g>\n<g id=\"clust2\" class=\"cluster\">\n<title>cluster_3</title>\n<polygon fill=\"none\" stroke=\"black\" stroke-dasharray=\"5,2\" points=\"26,-778.75 26,-859 206,-859 206,-778.75 26,-778.75\"/>\n<text text-anchor=\"middle\" x=\"53.12\" y=\"-843.6\" font-family=\"Times,serif\" font-size=\"12.00\">Conv2d</text>\n</g>\n<g id=\"clust3\" class=\"cluster\">\n<title>cluster_4</title>\n<polygon fill=\"none\" stroke=\"black\" stroke-dasharray=\"5,2\" points=\"26,-690.5 26,-770.75 206,-770.75 206,-690.5 26,-690.5\"/>\n<text text-anchor=\"middle\" x=\"49\" y=\"-755.35\" font-family=\"Times,serif\" font-size=\"12.00\">ReLU</text>\n</g>\n<g id=\"clust4\" class=\"cluster\">\n<title>cluster_5</title>\n<polygon fill=\"none\" stroke=\"black\" stroke-dasharray=\"5,2\" points=\"8,-379.5 8,-674.5 224,-674.5 224,-379.5 8,-379.5\"/>\n<text text-anchor=\"middle\" x=\"40.75\" y=\"-659.1\" font-family=\"Times,serif\" font-size=\"12.00\">Sequential</text>\n</g>\n<g id=\"clust5\" class=\"cluster\">\n<title>cluster_6</title>\n<polygon fill=\"none\" stroke=\"black\" stroke-dasharray=\"5,2\" points=\"26,-564 26,-644.25 206,-644.25 206,-564 26,-564\"/>\n<text text-anchor=\"middle\" x=\"53.12\" y=\"-628.85\" font-family=\"Times,serif\" font-size=\"12.00\">Conv2d</text>\n</g>\n<g id=\"clust6\" class=\"cluster\">\n<title>cluster_7</title>\n<polygon fill=\"none\" stroke=\"black\" stroke-dasharray=\"5,2\" points=\"26,-475.75 26,-556 206,-556 206,-475.75 26,-475.75\"/>\n<text text-anchor=\"middle\" x=\"49\" y=\"-540.6\" font-family=\"Times,serif\" font-size=\"12.00\">ReLU</text>\n</g>\n<g id=\"clust7\" class=\"cluster\">\n<title>cluster_8</title>\n<polygon fill=\"none\" stroke=\"black\" stroke-dasharray=\"5,2\" points=\"16,-387.5 16,-467.75 216,-467.75 216,-387.5 16,-387.5\"/>\n<text text-anchor=\"middle\" x=\"51.75\" y=\"-452.35\" font-family=\"Times,serif\" font-size=\"12.00\">MaxPool2d</text>\n</g>\n<g id=\"clust8\" class=\"cluster\">\n<title>cluster_9</title>\n<polygon fill=\"none\" stroke=\"black\" stroke-dasharray=\"5,2\" points=\"18,-8 18,-371.5 214,-371.5 214,-8 18,-8\"/>\n<text text-anchor=\"middle\" x=\"50.75\" y=\"-356.1\" font-family=\"Times,serif\" font-size=\"12.00\">Sequential</text>\n</g>\n<g id=\"clust9\" class=\"cluster\">\n<title>cluster_10</title>\n<polygon fill=\"none\" stroke=\"black\" stroke-dasharray=\"5,2\" points=\"26,-261 26,-341.25 206,-341.25 206,-261 26,-261\"/>\n<text text-anchor=\"middle\" x=\"50.12\" y=\"-325.85\" font-family=\"Times,serif\" font-size=\"12.00\">Flatten</text>\n</g>\n<g id=\"clust10\" class=\"cluster\">\n<title>cluster_11</title>\n<polygon fill=\"none\" stroke=\"black\" stroke-dasharray=\"5,2\" points=\"35,-172.75 35,-253 197,-253 197,-172.75 35,-172.75\"/>\n<text text-anchor=\"middle\" x=\"58.38\" y=\"-237.6\" font-family=\"Times,serif\" font-size=\"12.00\">Linear</text>\n</g>\n<g id=\"clust11\" class=\"cluster\">\n<title>cluster_12</title>\n<polygon fill=\"none\" stroke=\"black\" stroke-dasharray=\"5,2\" points=\"40,-16 40,-164.75 192,-164.75 192,-16 40,-16\"/>\n<text text-anchor=\"middle\" x=\"63.38\" y=\"-149.35\" font-family=\"Times,serif\" font-size=\"12.00\">Linear</text>\n</g>\n<!-- 0 -->\n<g id=\"node1\" class=\"node\">\n<title>0</title>\n<polygon fill=\"lightyellow\" stroke=\"none\" points=\"184.5,-929.75 47.5,-929.75 47.5,-897.25 184.5,-897.25 184.5,-929.75\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"47.5,-897.25 47.5,-929.75 108.5,-929.75 108.5,-897.25 47.5,-897.25\"/>\n<text text-anchor=\"start\" x=\"52.5\" y=\"-915.25\" font-family=\"Linux libertine\" font-size=\"10.00\">input&#45;tensor</text>\n<text text-anchor=\"start\" x=\"61.88\" y=\"-904\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:0</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"108.5,-897.25 108.5,-929.75 184.5,-929.75 184.5,-897.25 108.5,-897.25\"/>\n<text text-anchor=\"start\" x=\"113.5\" y=\"-909.62\" font-family=\"Linux libertine\" font-size=\"10.00\">(20, 3, 498, 13)</text>\n</g>\n<!-- 1 -->\n<g id=\"node2\" class=\"node\">\n<title>1</title>\n<polygon fill=\"aliceblue\" stroke=\"none\" points=\"198,-828.75 34,-828.75 34,-786.75 198,-786.75 198,-828.75\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"34,-786.75 34,-828.75 76,-828.75 76,-786.75 34,-786.75\"/>\n<text text-anchor=\"start\" x=\"39.25\" y=\"-809.5\" font-family=\"Linux libertine\" font-size=\"10.00\">conv2d</text>\n<text text-anchor=\"start\" x=\"38.88\" y=\"-798.25\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"76,-807.75 76,-828.75 119,-828.75 119,-807.75 76,-807.75\"/>\n<text text-anchor=\"start\" x=\"85.5\" y=\"-814.25\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"119,-807.75 119,-828.75 198,-828.75 198,-807.75 119,-807.75\"/>\n<text text-anchor=\"start\" x=\"124\" y=\"-814.25\" font-family=\"Linux libertine\" font-size=\"10.00\">(20, 3, 498, 13) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"76,-786.75 76,-807.75 119,-807.75 119,-786.75 76,-786.75\"/>\n<text text-anchor=\"start\" x=\"81\" y=\"-793.25\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"119,-786.75 119,-807.75 198,-807.75 198,-786.75 119,-786.75\"/>\n<text text-anchor=\"start\" x=\"124\" y=\"-793.25\" font-family=\"Linux libertine\" font-size=\"10.00\">(20, 80, 442, 8) </text>\n</g>\n<!-- 0&#45;&gt;1 -->\n<g id=\"edge1\" class=\"edge\">\n<title>0&#45;&gt;1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M116,-897.64C116,-882.67 116,-859.14 116,-840.04\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"119.5,-840.07 116,-830.07 112.5,-840.07 119.5,-840.07\"/>\n</g>\n<!-- 2 -->\n<g id=\"node3\" class=\"node\">\n<title>2</title>\n<polygon fill=\"aliceblue\" stroke=\"none\" points=\"198,-740.5 34,-740.5 34,-698.5 198,-698.5 198,-740.5\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"34,-698.5 34,-740.5 76,-740.5 76,-698.5 34,-698.5\"/>\n<text text-anchor=\"start\" x=\"47.12\" y=\"-721.25\" font-family=\"Linux libertine\" font-size=\"10.00\">relu</text>\n<text text-anchor=\"start\" x=\"38.88\" y=\"-710\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"76,-719.5 76,-740.5 119,-740.5 119,-719.5 76,-719.5\"/>\n<text text-anchor=\"start\" x=\"85.5\" y=\"-726\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"119,-719.5 119,-740.5 198,-740.5 198,-719.5 119,-719.5\"/>\n<text text-anchor=\"start\" x=\"124\" y=\"-726\" font-family=\"Linux libertine\" font-size=\"10.00\">(20, 80, 442, 8) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"76,-698.5 76,-719.5 119,-719.5 119,-698.5 76,-698.5\"/>\n<text text-anchor=\"start\" x=\"81\" y=\"-705\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"119,-698.5 119,-719.5 198,-719.5 198,-698.5 119,-698.5\"/>\n<text text-anchor=\"start\" x=\"124\" y=\"-705\" font-family=\"Linux libertine\" font-size=\"10.00\">(20, 80, 442, 8) </text>\n</g>\n<!-- 1&#45;&gt;2 -->\n<g id=\"edge2\" class=\"edge\">\n<title>1&#45;&gt;2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M116,-787.18C116,-776.67 116,-763.46 116,-751.58\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"119.5,-751.81 116,-741.81 112.5,-751.81 119.5,-751.81\"/>\n</g>\n<!-- 3 -->\n<g id=\"node4\" class=\"node\">\n<title>3</title>\n<polygon fill=\"aliceblue\" stroke=\"none\" points=\"198,-614 34,-614 34,-572 198,-572 198,-614\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"34,-572 34,-614 76,-614 76,-572 34,-572\"/>\n<text text-anchor=\"start\" x=\"39.25\" y=\"-594.75\" font-family=\"Linux libertine\" font-size=\"10.00\">conv2d</text>\n<text text-anchor=\"start\" x=\"38.88\" y=\"-583.5\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"76,-593 76,-614 119,-614 119,-593 76,-593\"/>\n<text text-anchor=\"start\" x=\"85.5\" y=\"-599.5\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"119,-593 119,-614 198,-614 198,-593 119,-593\"/>\n<text text-anchor=\"start\" x=\"124\" y=\"-599.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(20, 80, 442, 8) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"76,-572 76,-593 119,-593 119,-572 76,-572\"/>\n<text text-anchor=\"start\" x=\"81\" y=\"-578.5\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"119,-572 119,-593 198,-593 198,-572 119,-572\"/>\n<text text-anchor=\"start\" x=\"124\" y=\"-578.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(20, 80, 442, 6) </text>\n</g>\n<!-- 2&#45;&gt;3 -->\n<g id=\"edge3\" class=\"edge\">\n<title>2&#45;&gt;3</title>\n<path fill=\"none\" stroke=\"black\" d=\"M116,-698.77C116,-678.92 116,-648.02 116,-624.91\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"119.5,-625.15 116,-615.15 112.5,-625.15 119.5,-625.15\"/>\n</g>\n<!-- 4 -->\n<g id=\"node5\" class=\"node\">\n<title>4</title>\n<polygon fill=\"aliceblue\" stroke=\"none\" points=\"198,-525.75 34,-525.75 34,-483.75 198,-483.75 198,-525.75\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"34,-483.75 34,-525.75 76,-525.75 76,-483.75 34,-483.75\"/>\n<text text-anchor=\"start\" x=\"47.12\" y=\"-506.5\" font-family=\"Linux libertine\" font-size=\"10.00\">relu</text>\n<text text-anchor=\"start\" x=\"38.88\" y=\"-495.25\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"76,-504.75 76,-525.75 119,-525.75 119,-504.75 76,-504.75\"/>\n<text text-anchor=\"start\" x=\"85.5\" y=\"-511.25\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"119,-504.75 119,-525.75 198,-525.75 198,-504.75 119,-504.75\"/>\n<text text-anchor=\"start\" x=\"124\" y=\"-511.25\" font-family=\"Linux libertine\" font-size=\"10.00\">(20, 80, 442, 6) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"76,-483.75 76,-504.75 119,-504.75 119,-483.75 76,-483.75\"/>\n<text text-anchor=\"start\" x=\"81\" y=\"-490.25\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"119,-483.75 119,-504.75 198,-504.75 198,-483.75 119,-483.75\"/>\n<text text-anchor=\"start\" x=\"124\" y=\"-490.25\" font-family=\"Linux libertine\" font-size=\"10.00\">(20, 80, 442, 6) </text>\n</g>\n<!-- 3&#45;&gt;4 -->\n<g id=\"edge4\" class=\"edge\">\n<title>3&#45;&gt;4</title>\n<path fill=\"none\" stroke=\"black\" d=\"M116,-572.43C116,-561.92 116,-548.71 116,-536.83\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"119.5,-537.06 116,-527.06 112.5,-537.06 119.5,-537.06\"/>\n</g>\n<!-- 5 -->\n<g id=\"node6\" class=\"node\">\n<title>5</title>\n<polygon fill=\"aliceblue\" stroke=\"none\" points=\"208,-437.5 24,-437.5 24,-395.5 208,-395.5 208,-437.5\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"24,-395.5 24,-437.5 86,-437.5 86,-395.5 24,-395.5\"/>\n<text text-anchor=\"start\" x=\"28.75\" y=\"-418.25\" font-family=\"Linux libertine\" font-size=\"10.00\">max_pool2d</text>\n<text text-anchor=\"start\" x=\"38.88\" y=\"-407\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"86,-416.5 86,-437.5 129,-437.5 129,-416.5 86,-416.5\"/>\n<text text-anchor=\"start\" x=\"95.5\" y=\"-423\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"129,-416.5 129,-437.5 208,-437.5 208,-416.5 129,-416.5\"/>\n<text text-anchor=\"start\" x=\"134\" y=\"-423\" font-family=\"Linux libertine\" font-size=\"10.00\">(20, 80, 442, 6) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"86,-395.5 86,-416.5 129,-416.5 129,-395.5 86,-395.5\"/>\n<text text-anchor=\"start\" x=\"91\" y=\"-402\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"129,-395.5 129,-416.5 208,-416.5 208,-395.5 129,-395.5\"/>\n<text text-anchor=\"start\" x=\"134\" y=\"-402\" font-family=\"Linux libertine\" font-size=\"10.00\">(20, 80, 442, 2) </text>\n</g>\n<!-- 4&#45;&gt;5 -->\n<g id=\"edge5\" class=\"edge\">\n<title>4&#45;&gt;5</title>\n<path fill=\"none\" stroke=\"black\" d=\"M116,-484.18C116,-473.67 116,-460.46 116,-448.58\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"119.5,-448.81 116,-438.81 112.5,-448.81 119.5,-448.81\"/>\n</g>\n<!-- 6 -->\n<g id=\"node7\" class=\"node\">\n<title>6</title>\n<polygon fill=\"aliceblue\" stroke=\"none\" points=\"198,-311 34,-311 34,-269 198,-269 198,-311\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"34,-269 34,-311 76,-311 76,-269 34,-269\"/>\n<text text-anchor=\"start\" x=\"41.5\" y=\"-291.75\" font-family=\"Linux libertine\" font-size=\"10.00\">flatten</text>\n<text text-anchor=\"start\" x=\"38.88\" y=\"-280.5\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"76,-290 76,-311 119,-311 119,-290 76,-290\"/>\n<text text-anchor=\"start\" x=\"85.5\" y=\"-296.5\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"119,-290 119,-311 198,-311 198,-290 119,-290\"/>\n<text text-anchor=\"start\" x=\"124\" y=\"-296.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(20, 80, 442, 2) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"76,-269 76,-290 119,-290 119,-269 76,-269\"/>\n<text text-anchor=\"start\" x=\"81\" y=\"-275.5\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"119,-269 119,-290 198,-290 198,-269 119,-269\"/>\n<text text-anchor=\"start\" x=\"132.62\" y=\"-275.5\" font-family=\"Linux libertine\" font-size=\"10.00\">(20, 70720) </text>\n</g>\n<!-- 5&#45;&gt;6 -->\n<g id=\"edge6\" class=\"edge\">\n<title>5&#45;&gt;6</title>\n<path fill=\"none\" stroke=\"black\" d=\"M116,-395.77C116,-375.92 116,-345.02 116,-321.91\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"119.5,-322.15 116,-312.15 112.5,-322.15 119.5,-322.15\"/>\n</g>\n<!-- 7 -->\n<g id=\"node8\" class=\"node\">\n<title>7</title>\n<polygon fill=\"aliceblue\" stroke=\"none\" points=\"189,-222.75 43,-222.75 43,-180.75 189,-180.75 189,-222.75\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"43,-180.75 43,-222.75 85,-222.75 85,-180.75 43,-180.75\"/>\n<text text-anchor=\"start\" x=\"52.38\" y=\"-203.5\" font-family=\"Linux libertine\" font-size=\"10.00\">linear</text>\n<text text-anchor=\"start\" x=\"47.88\" y=\"-192.25\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"85,-201.75 85,-222.75 128,-222.75 128,-201.75 85,-201.75\"/>\n<text text-anchor=\"start\" x=\"94.5\" y=\"-208.25\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"128,-201.75 128,-222.75 189,-222.75 189,-201.75 128,-201.75\"/>\n<text text-anchor=\"start\" x=\"132.62\" y=\"-208.25\" font-family=\"Linux libertine\" font-size=\"10.00\">(20, 70720) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"85,-180.75 85,-201.75 128,-201.75 128,-180.75 85,-180.75\"/>\n<text text-anchor=\"start\" x=\"90\" y=\"-187.25\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"128,-180.75 128,-201.75 189,-201.75 189,-180.75 128,-180.75\"/>\n<text text-anchor=\"start\" x=\"137.88\" y=\"-187.25\" font-family=\"Linux libertine\" font-size=\"10.00\">(20, 500) </text>\n</g>\n<!-- 6&#45;&gt;7 -->\n<g id=\"edge7\" class=\"edge\">\n<title>6&#45;&gt;7</title>\n<path fill=\"none\" stroke=\"black\" d=\"M116,-269.43C116,-258.92 116,-245.71 116,-233.83\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"119.5,-234.06 116,-224.06 112.5,-234.06 119.5,-234.06\"/>\n</g>\n<!-- 8 -->\n<g id=\"node9\" class=\"node\">\n<title>8</title>\n<polygon fill=\"aliceblue\" stroke=\"none\" points=\"184,-134.5 48,-134.5 48,-92.5 184,-92.5 184,-134.5\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"48,-92.5 48,-134.5 90,-134.5 90,-92.5 48,-92.5\"/>\n<text text-anchor=\"start\" x=\"57.38\" y=\"-115.25\" font-family=\"Linux libertine\" font-size=\"10.00\">linear</text>\n<text text-anchor=\"start\" x=\"52.88\" y=\"-104\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:3</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"90,-113.5 90,-134.5 133,-134.5 133,-113.5 90,-113.5\"/>\n<text text-anchor=\"start\" x=\"99.5\" y=\"-120\" font-family=\"Linux libertine\" font-size=\"10.00\">input:</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"133,-113.5 133,-134.5 184,-134.5 184,-113.5 133,-113.5\"/>\n<text text-anchor=\"start\" x=\"137.88\" y=\"-120\" font-family=\"Linux libertine\" font-size=\"10.00\">(20, 500) </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"90,-92.5 90,-113.5 133,-113.5 133,-92.5 90,-92.5\"/>\n<text text-anchor=\"start\" x=\"95\" y=\"-99\" font-family=\"Linux libertine\" font-size=\"10.00\">output: </text>\n<polygon fill=\"none\" stroke=\"black\" points=\"133,-92.5 133,-113.5 184,-113.5 184,-92.5 133,-92.5\"/>\n<text text-anchor=\"start\" x=\"140.5\" y=\"-99\" font-family=\"Linux libertine\" font-size=\"10.00\">(20, 50) </text>\n</g>\n<!-- 7&#45;&gt;8 -->\n<g id=\"edge8\" class=\"edge\">\n<title>7&#45;&gt;8</title>\n<path fill=\"none\" stroke=\"black\" d=\"M116,-181.18C116,-170.67 116,-157.46 116,-145.58\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"119.5,-145.81 116,-135.81 112.5,-145.81 119.5,-145.81\"/>\n</g>\n<!-- 9 -->\n<g id=\"node10\" class=\"node\">\n<title>9</title>\n<polygon fill=\"lightyellow\" stroke=\"none\" points=\"171,-56.5 61,-56.5 61,-24 171,-24 171,-56.5\"/>\n<polygon fill=\"none\" stroke=\"black\" points=\"61,-24 61,-56.5 128,-56.5 128,-24 61,-24\"/>\n<text text-anchor=\"start\" x=\"66\" y=\"-42\" font-family=\"Linux libertine\" font-size=\"10.00\">output&#45;tensor</text>\n<text text-anchor=\"start\" x=\"78.38\" y=\"-30.75\" font-family=\"Linux libertine\" font-size=\"10.00\">depth:0</text>\n<polygon fill=\"none\" stroke=\"black\" points=\"128,-24 128,-56.5 171,-56.5 171,-24 128,-24\"/>\n<text text-anchor=\"start\" x=\"133\" y=\"-36.38\" font-family=\"Linux libertine\" font-size=\"10.00\">(20, 50)</text>\n</g>\n<!-- 8&#45;&gt;9 -->\n<g id=\"edge9\" class=\"edge\">\n<title>8&#45;&gt;9</title>\n<path fill=\"none\" stroke=\"black\" d=\"M116,-92.65C116,-84.91 116,-75.91 116,-67.63\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"119.5,-67.76 116,-57.76 112.5,-67.76 119.5,-67.76\"/>\n</g>\n</g>\n</svg>\n",
      "text/plain": "<graphviz.graphs.Digraph at 0x3867c1490>"
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_graph = draw_graph(viz_model,input_data,expand_nested=True, roll=True,graph_name='MLP',hide_inner_tensors=True,hide_module_functions=False)\n",
    "model_graph.visual_graph"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-17T11:50:11.028009Z",
     "start_time": "2024-06-17T11:50:10.854380Z"
    }
   },
   "id": "8921d8777315dc75"
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "outputs": [],
   "source": [
    "#acc_funcc = Accuracy(task=\"multiclass\", num_classes=3)\n",
    "#acc_funcc(torch.Tensor([1,2,3,3]),torch.Tensor([1,2,3,9]))*100"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-17T11:50:12.318851Z",
     "start_time": "2024-06-17T11:50:12.311663Z"
    }
   },
   "id": "96c737ebbd1b3b79"
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-17T11:50:13.740773Z",
     "start_time": "2024-06-17T11:50:13.735912Z"
    }
   },
   "id": "d4410655f408d012"
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================================================================================================================================================================================\n",
      "Layer (type:depth-idx)                   Input Shape               Output Shape              Kernel Shape              Param #                   Param %                   Mult-Adds                 Trainable\n",
      "=======================================================================================================================================================================================================================\n",
      "PiczakRec                                [20, 3, 498, 13]          [20, 50]                  --                        --                             --                   --                        True\n",
      "Sequential: 1-1                        [20, 3, 498, 13]          [20, 80, 442, 8]          --                        --                             --                   --                        True\n",
      "    Conv2d: 2-1                       [20, 3, 498, 13]          [20, 80, 442, 8]          [57, 6]                   82,160                      0.23%                   5,810,355,200             True\n",
      "    ReLU: 2-2                         [20, 80, 442, 8]          [20, 80, 442, 8]          --                        --                             --                   --                        --\n",
      "Sequential: 1-2                        [20, 80, 442, 8]          [20, 80, 442, 2]          --                        --                             --                   --                        True\n",
      "    Conv2d: 2-3                       [20, 80, 442, 8]          [20, 80, 442, 6]          [1, 3]                    19,280                      0.05%                   1,022,611,200             True\n",
      "    ReLU: 2-4                         [20, 80, 442, 6]          [20, 80, 442, 6]          --                        --                             --                   --                        --\n",
      "    MaxPool2d: 2-5                    [20, 80, 442, 6]          [20, 80, 442, 2]          [1, 3]                    --                             --                   --                        --\n",
      "Sequential: 1-3                        [20, 80, 442, 2]          [20, 50]                  --                        --                             --                   --                        True\n",
      "    Flatten: 2-6                      [20, 80, 442, 2]          [20, 70720]               --                        --                             --                   --                        --\n",
      "    Linear: 2-7                       [20, 70720]               [20, 500]                 --                        35,360,500                 99.64%                   707,210,000               True\n",
      "    Linear: 2-8                       [20, 500]                 [20, 50]                  --                        25,050                      0.07%                   501,000                   True\n",
      "=======================================================================================================================================================================================================================\n",
      "Total params: 35,486,990\n",
      "Trainable params: 35,486,990\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (Units.GIGABYTES): 7.54\n",
      "=======================================================================================================================================================================================================================\n",
      "Input size (MB): 1.55\n",
      "Forward/backward pass size (MB): 79.29\n",
      "Params size (MB): 141.95\n",
      "Estimated Total Size (MB): 222.80\n",
      "=======================================================================================================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "print(summary(viz_model, input_size=(N,C,H,W), col_names =[\"input_size\",\"output_size\",\"kernel_size\",\"num_params\",\"params_percent\",\"mult_adds\",\"trainable\"]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-17T11:50:14.730473Z",
     "start_time": "2024-06-17T11:50:14.600282Z"
    }
   },
   "id": "a603f7cb69b64dad"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-17T11:45:47.335198Z"
    }
   },
   "id": "8ef03ccce7341e78"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
