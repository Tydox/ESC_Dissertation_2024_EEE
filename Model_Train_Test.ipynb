{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-26T16:41:42.821247Z",
     "start_time": "2024-07-26T16:41:42.807926Z"
    }
   },
   "outputs": [],
   "source": [
    "# note: text\n",
    "# fixed: text\n",
    "# fix me: text\n",
    "# error: text\n",
    "# summary: text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "#Loader function for Pytorch Dataset Folder thingy\n",
    "def load_data(path: str):\n",
    "    #print(f\"Loading file: {path}\")\n",
    "    tensor = torch.load(path)\n",
    "    #tensor = tensor.float()\n",
    "    #print(f\"Loaded tensor type: {type(tensor)} {tensor.type()}\")\n",
    "    return tensor\n",
    "\n",
    "\n",
    "#ERROR DOESNT FULLY WORK WITH DATASET - IDK WHY - I GAVE UP FOR NOW\n",
    "#FIXME THIS DOES WORK AS A REGULAR REMAP AND I USE THIS FOR PRINTING DATA\n",
    "#NOTE TO SELF: DO NOT DELETE THIS FUNCTION\n",
    "# Define a custom transform to convert labels from float to int\n",
    "def label_remap(label):\n",
    "    label_mapping = {\n",
    "            0: 47,            1: 23,            2: 27,            3: 34,            4: 43,\n",
    "            5: 5,            6: 41,            7: 14,            8: 46,            9: 22,\n",
    "            10: 37,            11: 38,            12: 24,            13: 3,            14: 12,\n",
    "            15: 13,            16: 9,            17: 20,            18: 0,            19: 33,\n",
    "            20: 30,            21: 29,            22: 44,            23: 48,            24: 25,\n",
    "            25: 4,            26: 39,            27: 49,            28: 40,            29: 6,\n",
    "            30: 7,            31: 32,            32: 26,            33: 31,            34: 2,\n",
    "            35: 17,            36: 10,            37: 1,            38: 11,            39: 8,\n",
    "            40: 42,            41: 21,            42: 28,            43: 19,            44: 18,\n",
    "            45: 45,            46: 36,            47: 35,            48: 15,            49: 16\n",
    "    }\n",
    "    return torch.tensor(int(label_mapping[label]))\n",
    "\n",
    "\n",
    "#Summary: Print All Samples in Dataloader\n",
    "#Summary: Data Label OG = this is the published index labling, dog = 4\n",
    "#Summary; because pytorch sorts the data, dog = 18 in Dataloader,\n",
    "#Summary: so if i want to double check that the labels are correct, I have to use label_remap() function to convert the pytorch label number to the original\n",
    "#Summary: this doesnt really matter, all the code below was to just do a double check that everything is correct\n",
    "\n",
    "def print_data_loader(_dataloader,_stop,class_names):\n",
    "    if _dataloader.batch_size >1:\n",
    "        print(\"Sorry, This function doesn't support batch size dataset, please use batch = 1\")\n",
    "        return\n",
    "    \n",
    "    _idx =          f\"{'#':<{4}} | \"\n",
    "    _dshape =          f\"{'Data Shape:[N, C,  H,   W]':<{24}} | \"\n",
    "    _lshape =          f\"{'Label Shape':<{15}} | \"\n",
    "    _ddtype =          f\"{'Data DataType':<{13}} | \"\n",
    "    _dlabel1 =         f\"{'Data Label OG':<{13}} | \"\n",
    "    _dlabel2 =         f\"{'Data Label Py':<{13}} | \"\n",
    "    _dlabel3 =         f\"{'Data Label ':<{20}} | \"\n",
    "    _ldtype =          f\"{'Label Type':<{22}} | \"\n",
    "    _dpath =           f\"{'Data Path + Label PyTorch Value':<{60}} | \"\n",
    "    \n",
    "    print(f\"{_idx}{_dshape}{_lshape}{_ddtype}{_dlabel1}{_dlabel2}{_dlabel3}{_dpath}{_ldtype}\")\n",
    "    \n",
    "    #Note: CREATE AN ITERATOR FOR DATALOADER\n",
    "    _data_iter = iter(_dataloader)\n",
    "    #next(_data_iter)\n",
    "    counter = 1 #counter when to stop for loop\n",
    "    #NOTE: GO OVER ALL SAMPLES IN ITERATOR\n",
    "    for (_data, _label) in _data_iter:\n",
    "        #_data_iter = iter(test_dataloader)\n",
    "        _rnd_idx = _data_iter._sampler_iter.gi_frame.f_locals['idx']\n",
    "        _sample_idx = _data_iter._dataset.indices[_rnd_idx]\n",
    "        #numm = _data_iter._index_sampler.sampler.data_source.indices[num] #incorrect location\n",
    "        _path = test_dataset.dataset.samples[_sample_idx]\n",
    "        \n",
    "        #NOTE: This is for debug to check that it is the same samples values\n",
    "        #_amy_data = my_data_set[NUM2][0]\n",
    "        #_amy_dataog =  _data[0]\n",
    "        #diff =sum(sum(_amy_data - _amy_dataog)) \n",
    "        #print(diff)\n",
    "        #print(_path)\n",
    "        _idx =f\"{counter:<{4}} | \"\n",
    "        _dshape = f\"{str(_data.shape):<{24}} | \" # = [batch_size, color_channels, height, width]\"\n",
    "        _lshape = f\"{str(_label.shape):<{15}} | \"\n",
    "        _ddtype = f\"{str(_data.dtype):<{13}} | \"\n",
    "        _dlabel1 = f\"{str(label_remap(int(_label[0]))):<{13}} | \"\n",
    "        _dlabel2 = f\"{str(_label):<{13}} | \"\n",
    "        _dlabel3 = f\"{str(class_names[_label]):<{20}} | \"\n",
    "        _ldtype = f\"{str(type(_label)):<{22}} | \"\n",
    "        _dpath =   f\"{str(_path).split('/',6)[6]:<{60}} | \"\n",
    "    \n",
    "        print(f\"{_idx}{_dshape}{_lshape}{_ddtype}{_dlabel1}{_dlabel2}{_dlabel3}{_dpath}{_ldtype}\")\n",
    "        \n",
    "        if counter == _stop:\n",
    "            break\n",
    "        else:\n",
    "            counter=counter+1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-26T16:41:43.034331Z",
     "start_time": "2024-07-26T16:41:43.022430Z"
    }
   },
   "id": "55baaa3bcda72ffd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# ALL CODE ABOVE IS FUNCTIONS FROM MFCC_DATA_IMPORT"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "edb21a47bc95f30a"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "import os\n",
    "InputFolder =\"/Users/daniel/Desktop/Github/ESC_Dissertation_2024_EEE/MFCC/tensor3c/\"\n",
    "# Step 1: Create a dataset from the new organized folder\n",
    "\n",
    "#from torchvision import transforms\n",
    "#NHWC2NCHW = transforms.Compose([transforms.Lambda(lambda x: x.permute(0, 3, 1, 2))])  # from NHWC to NCHW\n",
    "# Define a custom transform to add the extra dimension\n",
    "# test_transform = transforms.Compose([\n",
    "#     transforms.Lambda(lambda x: x.unsqueeze(0))  # Adds an extra dimension, making it [1, C, H, W]\n",
    "# ])\n",
    "import torch\n",
    "from torchvision import datasets\n",
    "\n",
    "my_data_set = datasets.DatasetFolder(\n",
    "        root = InputFolder,\n",
    "        loader = load_data,\n",
    "        transform = None, #use \"test_transform\" only if using coeff because its missing channels=1 dimention  #our transformation for data\n",
    "        target_transform = None,\n",
    "        extensions = ('.pt',)\n",
    ")\n",
    "#my_data_set.class_to_idx\n",
    "#Step 2\n",
    "# Determine the sizes for training and testing splits\n",
    "# And Split the dataset\n",
    "\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "train_size = int(0.7 * len(my_data_set))\n",
    "test_size = len(my_data_set) - train_size\n",
    "\n",
    "train_dataset, test_dataset = random_split(my_data_set, [train_size, test_size])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-26T16:41:43.599446Z",
     "start_time": "2024-07-26T16:41:43.570430Z"
    }
   },
   "id": "e97881811308182d"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "#step 3\n",
    "# Turn train\\test Datasets into train\\test DataLoaders\n",
    "\n",
    "#import os\n",
    "#NUM_OF_WORKERS = os.cpu_count() #this is used on collab when I want to use all max cpu power\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "BATCH_SIZE = 10\n",
    "train_dataloader = DataLoader(dataset = train_dataset,\n",
    "                              batch_size = BATCH_SIZE,  # how many samples per batch?\n",
    "                              #num_workers=1,#ERROR THIS DOESNT WORK ON LAPTOP BUT WORKS ON COLLAB # how many CPU subprocesses to use for data loading? (higher = more)\n",
    "                              shuffle = True)  # shuffle the data?\n",
    "\n",
    "test_dataloader = DataLoader(dataset = test_dataset,\n",
    "                             batch_size = BATCH_SIZE,  # how many samples per batch?\n",
    "                             #num_workers=1,#ERROR THIS DOESNT WORK ON LAPTOP BUT WORKS ON COLLAB # how many CPU subprocesses to use for data loading? (higher = more)\n",
    "                             shuffle = True)  # shuffle the data?"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-26T16:41:43.859581Z",
     "start_time": "2024-07-26T16:41:43.850405Z"
    }
   },
   "id": "9f7f586a6ec2bbb6"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Class Label': Label Number \n",
      "{'airplane': 0, 'breathing': 1, 'brushing_teeth': 2, 'can_opening': 3, 'car_horn': 4, 'cat': 5, 'chainsaw': 6, 'chirping_birds': 7, 'church_bells': 8, 'clapping': 9, 'clock_alarm': 10, 'clock_tick': 11, 'coughing': 12, 'cow': 13, 'crackling_fire': 14, 'crickets': 15, 'crow': 16, 'crying_baby': 17, 'dog': 18, 'door_wood_creaks': 19, 'door_wood_knock': 20, 'drinking_sipping': 21, 'engine': 22, 'fireworks': 23, 'footsteps': 24, 'frog': 25, 'glass_breaking': 26, 'hand_saw': 27, 'helicopter': 28, 'hen': 29, 'insects': 30, 'keyboard_typing': 31, 'laughing': 32, 'mouse_click': 33, 'pig': 34, 'pouring_water': 35, 'rain': 36, 'rooster': 37, 'sea_waves': 38, 'sheep': 39, 'siren': 40, 'sneezing': 41, 'snoring': 42, 'thunderstorm': 43, 'toilet_flush': 44, 'train': 45, 'vacuum_cleaner': 46, 'washing_machine': 47, 'water_drops': 48, 'wind': 49}\n"
     ]
    }
   ],
   "source": [
    "class_names = my_data_set.classes\n",
    "class_dict = my_data_set.class_to_idx\n",
    "print(f\"'Class Label': Label Number \\n{class_dict}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-26T16:41:44.170460Z",
     "start_time": "2024-07-26T16:41:44.167326Z"
    }
   },
   "id": "ae10b1acb2c9da55"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train DataLoader Samples:\t140*10,\t\tTest DataLoader Samples:\t60*10.\n",
      "Train DataSet Samples:\t\t1400,\t\tTest DataSet Samples:\t\t600.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train DataLoader Samples:\\t{len(train_dataloader)}*{train_dataloader.batch_size},\\t\\tTest DataLoader Samples:\\t{len(test_dataloader)}*{test_dataloader.batch_size}.\")\n",
    "print(f\"Train DataSet Samples:\\t\\t{len(train_dataset)},\\t\\tTest DataSet Samples:\\t\\t{len(test_dataset)}.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-26T16:41:44.954437Z",
     "start_time": "2024-07-26T16:41:44.942384Z"
    }
   },
   "id": "d9d11625dbe18dbb"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorry, This function doesn't support batch size dataset, please use batch = 1\n"
     ]
    }
   ],
   "source": [
    "print_data_loader(test_dataloader, 1,class_names ) # DOESNT WORK WHEN BATCH SIZE IS > 1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-26T16:41:45.312270Z",
     "start_time": "2024-07-26T16:41:45.302546Z"
    }
   },
   "id": "d9209d1f27d7a9ec"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorry, This function doesn't support batch size dataset, please use batch = 1\n"
     ]
    }
   ],
   "source": [
    "print_data_loader(train_dataloader, 5,class_names )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-26T16:41:45.605794Z",
     "start_time": "2024-07-26T16:41:45.600919Z"
    }
   },
   "id": "acc591d6dc60be1a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# CREATING A MODEL USING PYTORCH SEQUENIAL"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3cfce6c3c2d50c01"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# Import torch\n",
    "import torch\n",
    "\n",
    "# Setup device agnostic code\n",
    "#device agnostic code - automatically set what cpu\\gpu to use for best performance\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Setup random seed\n",
    "#RANDOM_SEED = 42"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-26T16:41:47.342751Z",
     "start_time": "2024-07-26T16:41:47.339947Z"
    }
   },
   "id": "2ad523a37aaaac70"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchmetrics import Accuracy"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-26T16:41:48.477921Z",
     "start_time": "2024-07-26T16:41:47.829272Z"
    }
   },
   "id": "e073483ccd58375e"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "\n",
    "class PiczakRec(nn.Module):\n",
    "    def __init__(self,inputSize,outputSize,hiddenNeurons,filtersize,poolingsize,padsize,stridesize,flattensize):\n",
    "        super().__init__()\n",
    "\n",
    "        self.nnBlock1 = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=inputSize,out_channels=40,kernel_size=(8,1),padding=0),\n",
    "                nn.BatchNorm2d(40),\n",
    "                \n",
    "                nn.Conv2d(in_channels=40,out_channels=40,kernel_size=(8,1),padding=0),\n",
    "                nn.BatchNorm2d(40),\n",
    "                \n",
    "                nn.MaxPool2d(1,160),\n",
    "                \n",
    "\n",
    "                \n",
    "                nn.ReLU(),\n",
    "                #nn.MaxPool2d(kernel_size=(4,3),stride=(1,3)),\n",
    "        )    \n",
    "        \n",
    "        self.nnBlock2 = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=80,out_channels=80,kernel_size=(1,3),padding=0,stride = 1),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(kernel_size=(1,3),stride=(1,3))\n",
    "        )    \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=160,out_features=100),\n",
    "            #nn.Linear(in_features=5000,out_features=5000),\n",
    "            nn.Linear(in_features=100,out_features=50)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.nnBlock1(x)\n",
    "        #x = self.nnBlock2(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-26T16:41:49.468296Z",
     "start_time": "2024-07-26T16:41:49.456909Z"
    }
   },
   "id": "d1103327ceb4f064"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "inputSize=3#how many color channels, in my case 1\n",
    "outputSize=50\n",
    "hiddenNeurons=1\n",
    "filtersize=3\n",
    "poolingsize=2\n",
    "padsize=0\n",
    "stridesize=1\n",
    "flattensize=3528\n",
    "model = PiczakRec(inputSize,outputSize,hiddenNeurons,filtersize,poolingsize,padsize,stridesize,flattensize)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-26T16:41:51.461252Z",
     "start_time": "2024-07-26T16:41:51.448862Z"
    }
   },
   "id": "7381994b8e64d9a3"
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "#Summary: Change this model architecture to whatever you want and run all the code below\n",
    "class ModelV1(nn.Module):\n",
    "    def __init__(self,inputSize,outputSize,hiddenNeurons,filtersize,poolingsize,padsize,stridesize,flattensize):\n",
    "        super().__init__()\n",
    "\n",
    "        self.nnBlock1 = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=inputSize,out_channels=40,kernel_size=(8,1),padding=0),\n",
    "                nn.BatchNorm2d(40),\n",
    "                \n",
    "                nn.Conv2d(in_channels=40,out_channels=40,kernel_size=(8,1),padding=0),\n",
    "                nn.BatchNorm2d(40),\n",
    "                \n",
    "                nn.MaxPool2d(1,160),\n",
    "                \n",
    "\n",
    "                \n",
    "                nn.ReLU(),\n",
    "                #nn.MaxPool2d(kernel_size=(4,3),stride=(1,3)),\n",
    "        )    \n",
    "        \n",
    "        self.nnBlock2 = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=80,out_channels=80,kernel_size=(1,3),padding=0,stride = 1),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(kernel_size=(1,3),stride=(1,3))\n",
    "        )    \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=160,out_features=100),\n",
    "            #nn.Linear(in_features=5000,out_features=5000),\n",
    "            nn.Linear(in_features=100,out_features=50)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.nnBlock1(x)\n",
    "        #x = self.nnBlock2(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = ModelV1(inputSize,outputSize,hiddenNeurons,filtersize,poolingsize,padsize,stridesize,flattensize)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-22T18:43:18.356351Z"
    }
   },
   "id": "4edfb44bcd12e35a"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "expected 4D input (got 3D input)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[21], line 8\u001B[0m\n\u001B[1;32m      6\u001B[0m coeff,y \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mnext\u001B[39m(\u001B[38;5;28miter\u001B[39m(test_dataloader))\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mnumel(torch\u001B[38;5;241m.\u001B[39mtensor(coeff\u001B[38;5;241m.\u001B[39mshape)) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m4\u001B[39m:\n\u001B[0;32m----> 8\u001B[0m     model_pred_logits \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcoeff\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39msqueeze(dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m) \u001B[38;5;66;03m# make sure image is right shape + on right device\u001B[39;00m\n\u001B[1;32m      9\u001B[0m     model_pred_probs \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39msoftmax(model_pred_logits, dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m     10\u001B[0m     model_pred_label \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39margmax(model_pred_probs, dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "Cell \u001B[0;32mIn[19], line 33\u001B[0m, in \u001B[0;36mPiczakRec.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m     32\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[0;32m---> 33\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnnBlock1\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     34\u001B[0m     \u001B[38;5;66;03m#x = self.nnBlock2(x)\u001B[39;00m\n\u001B[1;32m     35\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclassifier(x)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/container.py:215\u001B[0m, in \u001B[0;36mSequential.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    213\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[1;32m    214\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[0;32m--> 215\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    216\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py:138\u001B[0m, in \u001B[0;36m_BatchNorm.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    137\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m--> 138\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_check_input_dim\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    140\u001B[0m     \u001B[38;5;66;03m# exponential_average_factor is set to self.momentum\u001B[39;00m\n\u001B[1;32m    141\u001B[0m     \u001B[38;5;66;03m# (when it is available) only so that it gets updated\u001B[39;00m\n\u001B[1;32m    142\u001B[0m     \u001B[38;5;66;03m# in ONNX graph when this node is exported to ONNX.\u001B[39;00m\n\u001B[1;32m    143\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmomentum \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py:416\u001B[0m, in \u001B[0;36mBatchNorm2d._check_input_dim\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    414\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_check_input_dim\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[1;32m    415\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28minput\u001B[39m\u001B[38;5;241m.\u001B[39mdim() \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m4\u001B[39m:\n\u001B[0;32m--> 416\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mexpected 4D input (got \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28minput\u001B[39m\u001B[38;5;241m.\u001B[39mdim()\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124mD input)\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mValueError\u001B[0m: expected 4D input (got 3D input)"
     ]
    }
   ],
   "source": [
    "#Note: Used for debugging\n",
    "\n",
    "#model.state_dict()\n",
    "#next(model.modules())\n",
    "# model.eval()\n",
    "# coeff,y = next(iter(test_dataloader))\n",
    "## if torch.numel(torch.tensor(coeff.shape)) == 4:\n",
    "##     model_pred_logits = model(coeff[0]).squeeze(dim=0) # make sure image is right shape + on right device\n",
    "##     model_pred_probs = torch.softmax(model_pred_logits, dim=1)\n",
    "##     model_pred_label = torch.argmax(model_pred_probs, dim=1)\n",
    "## else:\n",
    "#     model_pred_logits = model(coeff).squeeze(dim=0) # make sure image is right shape + on right device\n",
    "#     model_pred_probs = torch.softmax(model_pred_logits, dim=1)\n",
    "#     model_pred_label = torch.argmax(model_pred_probs, dim=1)\n",
    "# coeff.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-26T16:42:01.903275Z",
     "start_time": "2024-07-26T16:42:01.646325Z"
    }
   },
   "id": "6cbfda5aa4826fa8"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "b578d49407909372"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# INIT TENSORBOARD & SETUP\n",
    "Dashboard: [http://localhost:6006](http://localhost:6006)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b790c99c63949a3e"
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": "Launching TensorBoard..."
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch.utils.tensorboard\n",
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard\n",
    "# Stand Tensorboard\n",
    "%tensorboard --logdir=runs --reload_multifile True"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-22T18:43:20.835325Z",
     "start_time": "2024-06-22T18:43:19.808763Z"
    }
   },
   "id": "a7e9d44c10649ec4"
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "#Create a SummyWriter which is LOG FILE DATABASE for our model\n",
    "#CHANGE THE NAME BASED ON THE MODEL WE USE - DONT FORGET\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "# default `log_dir` is \"runs\" - we'll be more specific here\n",
    "#_MODEL_NAME_ = \"model1_test_trash\"\n",
    "#writer = SummaryWriter(\"runs/\" + _MODEL_NAME_)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-22T18:43:20.840472Z",
     "start_time": "2024-06-22T18:43:20.836904Z"
    }
   },
   "id": "24424be8f3c6f260"
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/50 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1e2dce52b1354d30989b48ab8a2e0f6b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/140 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "925c28c187d341af97429a76ae52ba5b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Loss: 4.033 | Test loss: 3.954 | Train Acc: 1.5 | Test Acc: 1.1666667461395264\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/140 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9e1cda92b5454b22982e7608d2f9478c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Loss: 3.877 | Test loss: 3.844 | Train Acc: 2.4285709857940674 | Test Acc: 1.8333336114883423\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/140 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2070aec42f4a4d15a1397ae6fcdf4117"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 | Loss: 3.835 | Test loss: 3.831 | Train Acc: 2.6428565979003906 | Test Acc: 0.3333333432674408\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/140 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fba41ab5ee454a439594e6e271a08c14"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 | Loss: 3.818 | Test loss: 3.853 | Train Acc: 3.428569793701172 | Test Acc: 0.8333333730697632\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/140 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5ec9bfe063d64ca3bae79f9c580e8687"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 | Loss: 3.796 | Test loss: 3.828 | Train Acc: 3.4999985694885254 | Test Acc: 0.6666666865348816\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/140 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6747c025162e49979568af6ee82e2a6e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 | Loss: 3.790 | Test loss: 3.835 | Train Acc: 3.428569793701172 | Test Acc: 1.0000001192092896\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/140 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6c032f6b4a9b4e8e94cece87e0a3b02a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 | Loss: 3.772 | Test loss: 3.834 | Train Acc: 4.142855167388916 | Test Acc: 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/140 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "51e547de73d8457d8978e1f04265ea70"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 | Loss: 3.784 | Test loss: 3.859 | Train Acc: 4.0714263916015625 | Test Acc: 2.6666669845581055\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/140 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "61c4533e8cc0479da644d8b4832db0da"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 | Loss: 3.777 | Test loss: 3.834 | Train Acc: 4.2142839431762695 | Test Acc: 7.6666646003723145\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/140 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c8ac0e55b9ac4ddb9e9f167ef8d7acf0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 | Loss: 3.769 | Test loss: 3.833 | Train Acc: 4.357141017913818 | Test Acc: 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/140 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a332c6be56ce4023840d224a588610d0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 | Loss: 3.758 | Test loss: 3.845 | Train Acc: 4.071426868438721 | Test Acc: 0.1666666716337204\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/140 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4be23d1d7893416ab663d063665cfc5c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11 | Loss: 3.755 | Test loss: 3.842 | Train Acc: 4.5714263916015625 | Test Acc: 1.0000001192092896\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/140 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9f566b5c11424403a8c72ea8cb6811df"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12 | Loss: 3.741 | Test loss: 3.843 | Train Acc: 4.499998092651367 | Test Acc: 0.6666666865348816\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/140 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "18a934ad6c1544648c45348b32135089"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13 | Loss: 3.758 | Test loss: 3.846 | Train Acc: 4.571426868438721 | Test Acc: 5.999998569488525\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/140 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ec6627bcbf874cd4985bd253341a65e4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14 | Loss: 3.731 | Test loss: 3.857 | Train Acc: 4.7142839431762695 | Test Acc: 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/140 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4970eba94e1b4d7e8274114bf9ad02ee"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15 | Loss: 3.738 | Test loss: 3.863 | Train Acc: 4.85714054107666 | Test Acc: 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/140 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9033f0cec5ba436ea71a229520f90a0f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16 | Loss: 3.735 | Test loss: 3.889 | Train Acc: 5.214282512664795 | Test Acc: 0.6666666865348816\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/140 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9354c77b81154a44905a0df774569eb9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17 | Loss: 3.739 | Test loss: 3.854 | Train Acc: 5.428568363189697 | Test Acc: 8.333330154418945\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/140 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4e5b2d5b4e7f4a56be4d4f2fcb4fd90a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18 | Loss: 3.728 | Test loss: 3.864 | Train Acc: 4.928569316864014 | Test Acc: 1.6666669845581055\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/140 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e87764006c894bafb6a4d9bc2d170c8e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19 | Loss: 3.715 | Test loss: 3.870 | Train Acc: 4.642855167388916 | Test Acc: 1.8333336114883423\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/140 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "299d06b4a1474d3e857742f56a5b5de2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20 | Loss: 3.700 | Test loss: 3.886 | Train Acc: 4.928569316864014 | Test Acc: 6.999998569488525\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/140 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "49094b83c676441d9ce82a7c5f53af7d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21 | Loss: 3.721 | Test loss: 3.844 | Train Acc: 5.571425914764404 | Test Acc: 1.3333334922790527\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/140 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "86ae9c7e1b624dcab963fcac4e7cd451"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22 | Loss: 3.715 | Test loss: 3.850 | Train Acc: 6.4285712242126465 | Test Acc: 1.1666667461395264\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/140 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8f180011efbb4179b8823f2f41578329"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23 | Loss: 3.710 | Test loss: 3.883 | Train Acc: 5.785712718963623 | Test Acc: 2.1666667461395264\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/140 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2a212f84758848109c20fbb845711ab4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24 | Loss: 3.706 | Test loss: 3.854 | Train Acc: 5.499997138977051 | Test Acc: 7.999997615814209\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/140 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "120f49fe05bd4ecba3d01798674d9969"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25 | Loss: 3.699 | Test loss: 3.861 | Train Acc: 5.571425437927246 | Test Acc: 0.5000000596046448\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/140 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dd2db87abe1744fead62968b82974951"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26 | Loss: 3.703 | Test loss: 3.877 | Train Acc: 5.999998569488525 | Test Acc: 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/140 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7dcd23a1ab494ae3ab63c9314854a767"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27 | Loss: 3.696 | Test loss: 3.872 | Train Acc: 5.785711288452148 | Test Acc: 1.8333336114883423\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/140 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "183c95b90ff14a398d4e8e8165d945ba"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28 | Loss: 3.693 | Test loss: 3.868 | Train Acc: 5.714282989501953 | Test Acc: 0.5000000596046448\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/140 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a7c9bcf98e524c289a8aa4c5c503b18a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29 | Loss: 3.682 | Test loss: 3.873 | Train Acc: 6.0714263916015625 | Test Acc: 3.8333334922790527\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/140 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "18c37097cb0542fa919960ff8aeeadbb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30 | Loss: 3.692 | Test loss: 3.869 | Train Acc: 6.214282989501953 | Test Acc: 0.1666666716337204\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/140 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2e70eed2183f41ada7897384f0f0eec5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 31 | Loss: 3.683 | Test loss: 3.902 | Train Acc: 5.999997615814209 | Test Acc: 0.8333333730697632\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/140 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "925e65ee9dd84708876cd9dbb52ea36c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 32 | Loss: 3.681 | Test loss: 3.906 | Train Acc: 6.357141017913818 | Test Acc: 1.0000001192092896\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/140 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8f4ad62aa3ed4fecbd1b178f83b589cb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 33 | Loss: 3.682 | Test loss: 3.903 | Train Acc: 5.714282989501953 | Test Acc: 1.5000001192092896\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/140 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9ee2e5b5a3fd4603ba3c43415f666f10"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 34 | Loss: 3.687 | Test loss: 3.885 | Train Acc: 6.428569793701172 | Test Acc: 1.1666667461395264\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/140 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bd124dc88da444bdb6ee84689857dc49"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 35 | Loss: 3.677 | Test loss: 3.875 | Train Acc: 5.714282989501953 | Test Acc: 2.333333730697632\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/140 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2480cdb4d346425488c2184931793c21"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 36 | Loss: 3.682 | Test loss: 3.884 | Train Acc: 5.714283466339111 | Test Acc: 5.166666030883789\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/140 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b11179bcc022435aaf098a4129fcb1d6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 37 | Loss: 3.678 | Test loss: 3.894 | Train Acc: 5.85714054107666 | Test Acc: 0.6666666865348816\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/140 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d7868de8468e4b13b9f0f0634c062651"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 38 | Loss: 3.673 | Test loss: 3.865 | Train Acc: 6.142856121063232 | Test Acc: 5.166666030883789\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/140 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "51426ccc5eec4efeba0a195b351a2072"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 39 | Loss: 3.676 | Test loss: 3.919 | Train Acc: 6.4285712242126465 | Test Acc: 0.6666666865348816\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/140 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0354df484d7643679aced2215a692c8f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 40 | Loss: 3.686 | Test loss: 3.944 | Train Acc: 5.999996662139893 | Test Acc: 2.1666669845581055\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/140 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "957950fb2beb4b2fa6da4319409ec47e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 41 | Loss: 3.666 | Test loss: 3.873 | Train Acc: 6.285712242126465 | Test Acc: 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/140 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "61f599547dac4391ae81c625be5d104b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 42 | Loss: 3.664 | Test loss: 3.943 | Train Acc: 6.9285712242126465 | Test Acc: 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/140 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "411c7218a8c541a78c6657c4f9b70d9d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 43 | Loss: 3.651 | Test loss: 3.910 | Train Acc: 7.0 | Test Acc: 1.5000001192092896\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/140 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "39828e4799ae41f98e10a1916499cc36"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 44 | Loss: 3.664 | Test loss: 3.934 | Train Acc: 6.785714626312256 | Test Acc: 3.1666674613952637\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/140 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "60ca142f90474f00980eb6f12997b042"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 45 | Loss: 3.667 | Test loss: 3.903 | Train Acc: 6.714284420013428 | Test Acc: 6.999997615814209\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/140 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d4d3aedf097b44528a4803d04c8dc42d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 46 | Loss: 3.667 | Test loss: 3.942 | Train Acc: 6.142856121063232 | Test Acc: 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/140 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8858a11260ce41c39369bef0c62e658b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 47 | Loss: 3.662 | Test loss: 3.934 | Train Acc: 6.428571701049805 | Test Acc: 4.5\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/140 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8ea17915f0b448ca909394364b06f0da"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 48 | Loss: 3.651 | Test loss: 3.914 | Train Acc: 7.142858982086182 | Test Acc: 0.1666666716337204\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/140 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "70bf653669ee415b81fc810c1f0ada0c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 49 | Loss: 3.651 | Test loss: 4.008 | Train Acc: 8.071428298950195 | Test Acc: 0.1666666716337204\n"
     ]
    }
   ],
   "source": [
    "# NOTE: SETUP METRICS USING TORCH LIBRARY - NOT SURE IF THIS MAKES IT EASIER OR NOT \n",
    "acc_func = Accuracy(task=\"multiclass\", num_classes=50).to(device)\n",
    "\n",
    "# NOTE: SETUP TQDM TO SHOW A PROGRESS BAR\n",
    "from tqdm.auto import tqdm \n",
    "\n",
    "#Summary 1: Create Model\n",
    "model = model.to(device)\n",
    "\n",
    "#Summary 2: Create Loss Function & Optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "#Summary 3: Setup SummaryWriter\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "_MODEL_NAME_ = \"model50_test_trash\" #NOTE: CHANGE ME\n",
    "writer = SummaryWriter(\"runs/\" + _MODEL_NAME_)\n",
    "\n",
    "### Training loop\n",
    "epochs = 50\n",
    "for epoch in tqdm(range(epochs)):\n",
    "\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    \n",
    "    #ii TRAINING loop\n",
    "    for batch, (X, y) in enumerate(tqdm(train_dataloader)):\n",
    "        #Note 0. Turn On Training Mode\n",
    "        model.train()\n",
    "        #Note 0.1. Put data on CPU\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        #Note 0.2. Check That Data has values - #ERROR This can be deleted quite honestly\n",
    "        if torch.isnan(X).any() or torch.isinf(X).any():\n",
    "            print(\"Data contains NaN or Inf values.\")\n",
    "\n",
    "        #Note 1. Forward pass\n",
    "        logits = model(X)\n",
    "        #Note 1.1 Convert Raw Logit Outputs to y predictions\n",
    "        y_pred = torch.softmax(logits, dim = 1)  #;print(y_pred.shape)\n",
    "        #Note 1.2 Convert y predictions to labels as y hat\n",
    "        y_hat = torch.argmax(y_pred, dim = 1)  #;print(y_hat.shape);print(y_hat)\n",
    "\n",
    "        #Note 2. Loss calculation\n",
    "        loss = loss_fn(logits, y)\n",
    "        #Note 2.1 Cumulatively add up the LOSS per epoch\n",
    "        train_loss += loss\n",
    "        #Note 2.1 Cumulatively add up the ACCURACY per epoch\n",
    "        train_acc += acc_func(y, y_hat)  #this slows down the runtime?\n",
    "\n",
    "        #Note 3. Optimizer zero grad - reset gradients\n",
    "        optimizer.zero_grad()\n",
    "        #Note 4. Loss backward - Backward propagation\n",
    "        loss.backward()\n",
    "        #Note 5. Step the optimizer - optimize\\upgade weight\\biases\\paramters of kernels\n",
    "        optimizer.step()\n",
    "\n",
    "    #Summary: Adjust TRAIN LOSS & ACCURACY for number of batches \n",
    "    #SUMMARY: Meaning -> Divide total TRAIN LOSS & ACC by length of TRAIN DATALOADER = (average loss per batch per epoch)\n",
    "    train_loss /= len(train_dataloader)\n",
    "    train_acc /= len(train_dataloader)\n",
    "\n",
    "    #ii TESTING loop\n",
    "    #Note 0. init Metric Params\n",
    "    test_loss = 0\n",
    "    test_acc = 0\n",
    "    \n",
    "    #Note 1. Put model in eval mode \n",
    "    model.eval()\n",
    "\n",
    "    #Note 1.1 Turn on inference mode - best way currently to do evaluation\n",
    "    with torch.inference_mode():\n",
    "        for batch, (X_test, y_test) in enumerate(test_dataloader):\n",
    "            #Note 2. Make sure test data on CPU\n",
    "            X_test, y_test = X_test.to(device), y_test.to(device)\n",
    "            #Note 3. Forward Pass\n",
    "            logits = model(X_test)\n",
    "            #Note 3.1 Convert Raw Logits (outputs) to y predictions\n",
    "            y_pred = torch.softmax(logits, dim = 1)  #;print(y_pred.shape)\n",
    "            #Note 3.2 Convert y predictions to y labels as y hat\n",
    "            y_hat = torch.argmax(y_pred, dim = 1)\n",
    "\n",
    "            \n",
    "            \n",
    "            #Note 4. Calculate The Loss\n",
    "            loss = loss_fn(logits, y_test)\n",
    "            #Note 4.1 Cumulatively add up the LOSS per epoch (all batches)\n",
    "            test_loss += loss\n",
    "            #Note 4.2 Cumulatively add up the ACCURACY per epoch (all batches)\n",
    "            test_acc += acc_func(y, y_hat)  #this slows down the runtime\n",
    "        \n",
    "        #Summary: Adjust TEST LOSS & ACCURACY for number of batches \n",
    "        #SUMMARY: Meaning -> Divide total TEST LOSS & ACC by length of TEST DATALOADER = (average loss per batch per epoch)\n",
    "        test_loss /= len(test_dataloader)\n",
    "        test_acc /= len(test_dataloader)\n",
    "\n",
    "    # Print out what's happening\n",
    "    print(f\"Epoch: {epoch} | Loss: {train_loss:.3f} | Test loss: {test_loss:.3f} | Train Acc: {train_acc * 100} | Test Acc: {test_acc * 100}\")\n",
    "    \n",
    "    #Note: Tensorboard Logging\n",
    "    #writer.add_scalar(\"Loss/Train\", train_loss, epoch)\n",
    "    #writer.add_scalar(\"Loss/Test\", test_loss, epoch)\n",
    "    #writer.add_scalar(\"Accuracy/Train\", train_acc*100, epoch)\n",
    "    #writer.add_scalar(tag = \"Accuracy/Test\", scalar_value = test_acc*100,global_step =  epoch)\n",
    "    \n",
    "    writer.add_scalars(\"Loss\",{'Train':train_loss},epoch)\n",
    "    writer.add_scalars(\"Loss\",{'Test':test_loss},epoch)\n",
    "\n",
    "    \n",
    "    writer.add_scalars(\"Accuracy\",{'Train':train_acc*100},epoch)\n",
    "    writer.add_scalars(\"Accuracy\",{'Test':test_acc*100},epoch)\n",
    "\n",
    "    writer.add_scalars(\"Train Loss/Accuracy\",{'Loss':train_loss},epoch)\n",
    "    writer.add_scalars(\"Train Loss/Accuracy\",{'Accuracy':train_acc*100},epoch)\n",
    "\n",
    "    writer.add_scalars(\"Test Loss/Accuracy\",{'Loss':test_loss},epoch)\n",
    "    writer.add_scalars(\"Test Loss/Accuracy\",{'Accuracy':test_acc*100},epoch)\n",
    "\n",
    "\n",
    "    #Call flush() method to make sure that all pending events have been written to disk.\n",
    "    writer.flush()\n",
    "\n",
    "writer.close()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-22T18:45:39.018335Z",
     "start_time": "2024-06-22T18:43:20.845363Z"
    }
   },
   "id": "6e03ff4858895a60"
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "#Add Model Structure To TensorBoard\n",
    "coeff,y = next(iter(test_dataloader))\n",
    "writer.add_graph(model, coeff.to(device))\n",
    "writer.close()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-22T20:53:11.782544Z",
     "start_time": "2024-06-22T20:53:11.714553Z"
    }
   },
   "id": "24b47ab974fa72e4"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "#acc_funcc = Accuracy(task=\"multiclass\", num_classes=3)\n",
    "#acc_funcc(torch.Tensor([1,2,3,3]),torch.Tensor([1,2,3,9]))*100"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-22T18:32:30.339271Z",
     "start_time": "2024-06-22T18:32:30.330101Z"
    }
   },
   "id": "96c737ebbd1b3b79"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "4636dbe132a09f17"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
